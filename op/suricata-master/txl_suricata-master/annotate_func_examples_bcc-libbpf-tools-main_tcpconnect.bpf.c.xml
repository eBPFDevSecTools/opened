<?xml version="1.0"?>
<doc>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline bool filter_port (__u16 port)" startline="52" endline="64">
static __always_inline bool filter_port (__u16 port)
{
    int i;
    if (filter_ports_len == 0)
        return false;
    for (i = 0; i < filter_ports_len && i < MAX_PORTS; i++) {
        if (port == filter_ports[i])
            return false;
    }
    return true;
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline int enter_tcp_connect (struct pt_regs *ctx, struct sock *sk)" startline="66" endline="83">
static __always_inline int enter_tcp_connect (struct pt_regs *ctx, struct sock *sk)
{
    __u64 pid_tgid = bpf_get_current_pid_tgid ();
    __u32 pid = pid_tgid >> 32;
    __u32 tid = pid_tgid;
    __u32 uid;
    if (filter_pid && pid != filter_pid)
        return 0;
    uid = bpf_get_current_uid_gid ();
    if (filter_uid != (uid_t) -1 && uid != filter_uid)
        return 0;
    bpf_map_update_elem (&sockets, &tid, &sk, 0);
    return 0;
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline void count_v4 (struct sock *sk, __u16 sport, __u16 dport)" startline="85" endline="98">
static __always_inline void count_v4 (struct sock *sk, __u16 sport, __u16 dport)
{
    struct ipv4_flow_key key = {}
    ;
    static __u64 zero;
    __u64 *val;
    BPF_CORE_READ_INTO (&key.saddr, sk, __sk_common.skc_rcv_saddr);
    BPF_CORE_READ_INTO (&key.daddr, sk, __sk_common.skc_daddr);
    key.sport = sport;
    key.dport = dport;
    val = bpf_map_lookup_or_try_init (& ipv4_count, & key, & zero);
    if (val)
        __atomic_add_fetch (val, 1, __ATOMIC_RELAXED);
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline void count_v6 (struct sock *sk, __u16 sport, __u16 dport)" startline="100" endline="116">
static __always_inline void count_v6 (struct sock *sk, __u16 sport, __u16 dport)
{
    struct ipv6_flow_key key = {}
    ;
    static const __u64 zero;
    __u64 *val;
    BPF_CORE_READ_INTO (&key.saddr, sk, __sk_common.skc_v6_rcv_saddr.in6_u.u6_addr32);
    BPF_CORE_READ_INTO (&key.daddr, sk, __sk_common.skc_v6_daddr.in6_u.u6_addr32);
    key.sport = sport;
    key.dport = dport;
    val = bpf_map_lookup_or_try_init (& ipv6_count, & key, & zero);
    if (val)
        __atomic_add_fetch (val, 1, __ATOMIC_RELAXED);
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline void trace_v4 (struct pt_regs *ctx, pid_t pid, struct sock *sk, __u16 sport, __u16 dport)" startline="118" endline="135">
static __always_inline void trace_v4 (struct pt_regs *ctx, pid_t pid, struct sock *sk, __u16 sport, __u16 dport)
{
    struct event event = {}
    ;
    event.af = AF_INET;
    event.pid = pid;
    event.uid = bpf_get_current_uid_gid ();
    event.ts_us = bpf_ktime_get_ns () / 1000;
    BPF_CORE_READ_INTO (&event.saddr_v4, sk, __sk_common.skc_rcv_saddr);
    BPF_CORE_READ_INTO (&event.daddr_v4, sk, __sk_common.skc_daddr);
    event.sport = sport;
    event.dport = dport;
    bpf_get_current_comm (event.task, sizeof (event.task));
    bpf_perf_event_output (ctx, &events, BPF_F_CURRENT_CPU, &event, sizeof (event));
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline void trace_v6 (struct pt_regs *ctx, pid_t pid, struct sock *sk, __u16 sport, __u16 dport)" startline="137" endline="156">
static __always_inline void trace_v6 (struct pt_regs *ctx, pid_t pid, struct sock *sk, __u16 sport, __u16 dport)
{
    struct event event = {}
    ;
    event.af = AF_INET6;
    event.pid = pid;
    event.uid = bpf_get_current_uid_gid ();
    event.ts_us = bpf_ktime_get_ns () / 1000;
    BPF_CORE_READ_INTO (&event.saddr_v6, sk, __sk_common.skc_v6_rcv_saddr.in6_u.u6_addr32);
    BPF_CORE_READ_INTO (&event.daddr_v6, sk, __sk_common.skc_v6_daddr.in6_u.u6_addr32);
    event.sport = sport;
    event.dport = dport;
    bpf_get_current_comm (event.task, sizeof (event.task));
    bpf_perf_event_output (ctx, &events, BPF_F_CURRENT_CPU, &event, sizeof (event));
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="static __always_inline int exit_tcp_connect (struct pt_regs *ctx, int ret, int ip_ver)" startline="158" endline="200">
static __always_inline int exit_tcp_connect (struct pt_regs *ctx, int ret, int ip_ver)
{
    __u64 pid_tgid = bpf_get_current_pid_tgid ();
    __u32 pid = pid_tgid >> 32;
    __u32 tid = pid_tgid;
    struct sock **skpp;
    struct sock *sk;
    __u16 sport = 0;
    __u16 dport;
    skpp = bpf_map_lookup_elem (& sockets, & tid);
    if (!skpp)
        return 0;
    if (ret)
        goto end;
    sk = *skpp;
    if (source_port)
        BPF_CORE_READ_INTO (&sport, sk, __sk_common.skc_num);
    BPF_CORE_READ_INTO (&dport, sk, __sk_common.skc_dport);
    if (filter_port (dport))
        goto end;
    if (do_count) {
        if (ip_ver == 4)
            count_v4 (sk, sport, dport);
        else
            count_v6 (sk, sport, dport);
    }
    else {
        if (ip_ver == 4)
            trace_v4 (ctx, pid, sk, sport, dport);
        else
            trace_v6 (ctx, pid, sk, sport, dport);
    }
end :
    bpf_map_delete_elem (&sockets, &tid);
    return 0;
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="int BPF_KPROBE (tcp_v4_connect, struct sock *sk)" startline="203" endline="206">
int BPF_KPROBE (tcp_v4_connect, struct sock *sk)
{
    return enter_tcp_connect (ctx, sk);
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="int BPF_KRETPROBE (tcp_v4_connect_ret, int ret)" startline="209" endline="212">
int BPF_KRETPROBE (tcp_v4_connect_ret, int ret)
{
    return exit_tcp_connect (ctx, ret, 4);
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="int BPF_KPROBE (tcp_v6_connect, struct sock *sk)" startline="215" endline="218">
int BPF_KPROBE (tcp_v6_connect, struct sock *sk)
{
    return enter_tcp_connect (ctx, sk);
}
</source>
<source file="/home/sayandes/opened_extraction/examples/bcc-libbpf-tools-main/tcpconnect.bpf.c" funcheader="int BPF_KRETPROBE (tcp_v6_connect_ret, int ret)" startline="221" endline="224">
int BPF_KRETPROBE (tcp_v6_connect_ret, int ret)
{
    return exit_tcp_connect (ctx, ret, 6);
}
</source>
</doc>
