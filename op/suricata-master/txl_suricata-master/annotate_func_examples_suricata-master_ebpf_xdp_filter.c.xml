<?xml version="1.0"?>
<doc>
<source file="/home/sayandes/opened_extraction/examples/suricata-master/ebpf/xdp_filter.c" funcheader="static __always_inline int get_sport (void *trans_data, void *data_end, __u8 protocol)" startline="191" endline="211">
static __always_inline int get_sport (void *trans_data, void *data_end, __u8 protocol)
{
    struct tcphdr *th;
    struct udphdr *uh;
    switch (protocol) {
    case IPPROTO_TCP :
        th = (struct tcphdr *) trans_data;
        if ((void *) (th + 1) > data_end)
            return -1;
        return th->source;
    case IPPROTO_UDP :
        uh = (struct udphdr *) trans_data;
        if ((void *) (uh + 1) > data_end)
            return -1;
        return uh->source;
    default :
        return 0;
    }
}
</source>
<source file="/home/sayandes/opened_extraction/examples/suricata-master/ebpf/xdp_filter.c" funcheader="static __always_inline int get_dport (void *trans_data, void *data_end, __u8 protocol)" startline="213" endline="233">
static __always_inline int get_dport (void *trans_data, void *data_end, __u8 protocol)
{
    struct tcphdr *th;
    struct udphdr *uh;
    switch (protocol) {
    case IPPROTO_TCP :
        th = (struct tcphdr *) trans_data;
        if ((void *) (th + 1) > data_end)
            return -1;
        return th->dest;
    case IPPROTO_UDP :
        uh = (struct udphdr *) trans_data;
        if ((void *) (uh + 1) > data_end)
            return -1;
        return uh->dest;
    default :
        return 0;
    }
}
</source>
<source file="/home/sayandes/opened_extraction/examples/suricata-master/ebpf/xdp_filter.c" funcheader="static int __always_inline filter_ipv4 (struct xdp_md *ctx, void *data, __u64 nh_off, void *data_end, __u16 vlan0, __u16 vlan1)" startline="235" endline="377">
static int __always_inline filter_ipv4 (struct xdp_md *ctx, void *data, __u64 nh_off, void *data_end, __u16 vlan0, __u16 vlan1)
{
    struct iphdr *iph = data + nh_off;
    int dport;
    int sport;
    struct flowv4_keys tuple;
    struct pair *value;

#if BUILD_CPUMAP || GOT_TX_PEER
    __u32 key0 = 0;

#endif

#if ENCRYPTED_TLS_BYPASS
    __u32 key1 = 0;
    __u32 *tls_count = NULL;

#endif

#if BUILD_CPUMAP
    __u32 cpu_dest;
    __u32 *cpu_max = bpf_map_lookup_elem (&cpus_count, &key0);
    __u32 *cpu_selected;
    __u32 cpu_hash;

#endif

#if GOT_TX_PEER
    int *iface_peer;
    int tx_port = 0;

#endif
    if ((void *) (iph + 1) > data_end)
        return XDP_PASS;
    if (iph->protocol == IPPROTO_TCP) {
        tuple.ip_proto = 1;
    }
    else {
        tuple.ip_proto = 0;
    }
    tuple.src = iph->saddr;
    tuple.dst = iph->daddr;
    dport = get_dport (iph + 1, data_end, iph -> protocol);
    if (dport == -1)
        return XDP_PASS;
    sport = get_sport (iph + 1, data_end, iph -> protocol);
    if (sport == -1)
        return XDP_PASS;
    tuple.port16[0] = (__u16) sport;
    tuple.port16[1] = (__u16) dport;
    tuple.vlan0 = vlan0;
    tuple.vlan1 = vlan1;
    value = bpf_map_lookup_elem (& flow_table_v4, & tuple);

#if 0
    {
        char fmt [] = "Current flow src: %u:%d\n";
        char fmt1 [] = "Current flow dst: %u:%d\n";
        bpf_trace_printk (fmt, sizeof (fmt), tuple.src, tuple.port16[0]);
        bpf_trace_printk (fmt1, sizeof (fmt1), tuple.dst, tuple.port16[1]);
    }

#endif
    if (value) {

#if 0
        char fmt [] = "Found flow v4: %u %d -> %d\n";
        bpf_trace_printk (fmt, sizeof (fmt), tuple.src, sport, dport);
        char fmt [] = "Data: t:%lu p:%lu n:%lu\n";
        bpf_trace_printk (fmt, sizeof (fmt), value->time, value->packets, value->bytes);

#endif

#if USE_PERCPU_HASH
        value->packets++;
        value->bytes += data_end - data;

#else
        __sync_fetch_and_add (&value->packets, 1);
        __sync_fetch_and_add (&value->bytes, data_end - data);

#endif

#if GOT_TX_PEER
        iface_peer = bpf_map_lookup_elem (& tx_peer_int, & key0);
        if (!iface_peer) {
            return XDP_DROP;
        }
        else {
            return bpf_redirect_map (&tx_peer, tx_port, 0);
        }

#else
        return XDP_DROP;

#endif
    }

#if ENCRYPTED_TLS_BYPASS
    if ((dport == __constant_ntohs (443)) || (sport == __constant_ntohs (443))) {
        __u8 *app_data;
        nh_off += sizeof (struct iphdr) + sizeof (struct tcphdr);
        if (data_end > data + nh_off + 4) {
            app_data = data + nh_off;
            if (app_data[0] == 0x17 && app_data[1] == 0x3 && app_data[2] == 0x3) {
                tls_count = bpf_map_lookup_elem (& tls_bypass_count, & key1);
                if (tls_count) {

#if USE_PERCPU_HASH
                    tls_count++;

#else
                    __sync_fetch_and_add (tls_count, 1);

#endif
                }

#if GOT_TX_PEER
                iface_peer = bpf_map_lookup_elem (& tx_peer_int, & key0);
                if (!iface_peer) {
                    return XDP_DROP;
                }
                else {
                    return bpf_redirect_map (&tx_peer, tx_port, 0);
                }

#else
                return XDP_DROP;

#endif
            }
        }
    }

#endif

#if BUILD_CPUMAP
    cpu_hash = tuple.src + tuple.dst;
    cpu_hash = SuperFastHash ((char *) & cpu_hash, 4, INITVAL + iph -> protocol);
    if (cpu_max && *cpu_max) {
        cpu_dest = cpu_hash % *cpu_max;
        cpu_selected = bpf_map_lookup_elem (& cpus_available, & cpu_dest);
        if (!cpu_selected)
            return XDP_ABORTED;
        cpu_dest = *cpu_selected;
        return bpf_redirect_map (&cpu_map, cpu_dest, 0);
    }
    else {
        return XDP_PASS;
    }

#else

#if RSS_QUEUE_NUMBERS
    __u32 xdp_hash = tuple.src + tuple.dst;
    xdp_hash = SuperFastHash ((char *) & xdp_hash, 4, INITVAL + iph -> protocol);
    ctx->rx_queue_index = xdp_hash % RSS_QUEUE_NUMBERS;

#endif
    return XDP_PASS;

#endif
}
</source>
<source file="/home/sayandes/opened_extraction/examples/suricata-master/ebpf/xdp_filter.c" funcheader="static int __always_inline filter_ipv6 (struct xdp_md *ctx, void *data, __u64 nh_off, void *data_end, __u16 vlan0, __u16 vlan1)" startline="379" endline="483">
static int __always_inline filter_ipv6 (struct xdp_md *ctx, void *data, __u64 nh_off, void *data_end, __u16 vlan0, __u16 vlan1)
{
    struct ipv6hdr *ip6h = data + nh_off;
    int dport;
    int sport;
    struct flowv6_keys tuple;
    struct pair *value;

#if BUILD_CPUMAP || GOT_TX_PEER
    __u32 key0 = 0;

#endif

#if BUILD_CPUMAP
    __u32 cpu_dest;
    int *cpu_max = bpf_map_lookup_elem (&cpus_count, &key0);
    __u32 *cpu_selected;
    __u32 cpu_hash;

#endif

#if GOT_TX_PEER
    int tx_port = 0;
    int *iface_peer;

#endif
    if ((void *) (ip6h + 1) > data_end)
        return 0;
    if (!((ip6h->nexthdr == IPPROTO_UDP) || (ip6h->nexthdr == IPPROTO_TCP)))
        return XDP_PASS;
    dport = get_dport (ip6h + 1, data_end, ip6h -> nexthdr);
    if (dport == -1)
        return XDP_PASS;
    sport = get_sport (ip6h + 1, data_end, ip6h -> nexthdr);
    if (sport == -1)
        return XDP_PASS;
    if (ip6h->nexthdr == IPPROTO_TCP) {
        tuple.ip_proto = 1;
    }
    else {
        tuple.ip_proto = 0;
    }
    __builtin_memcpy (tuple.src, ip6h->saddr.s6_addr32, sizeof (tuple.src));
    __builtin_memcpy (tuple.dst, ip6h->daddr.s6_addr32, sizeof (tuple.dst));
    tuple.port16[0] = sport;
    tuple.port16[1] = dport;
    tuple.vlan0 = vlan0;
    tuple.vlan1 = vlan1;
    value = bpf_map_lookup_elem (& flow_table_v6, & tuple);
    if (value) {

#if 0
        char fmt6 [] = "Found IPv6 flow: %d -> %d\n";
        bpf_trace_printk (fmt6, sizeof (fmt6), sport, dport);

#endif

#if USE_PERCPU_HASH
        value->packets++;
        value->bytes += data_end - data;

#else
        __sync_fetch_and_add (&value->packets, 1);
        __sync_fetch_and_add (&value->bytes, data_end - data);

#endif

#if GOT_TX_PEER
        iface_peer = bpf_map_lookup_elem (& tx_peer_int, & key0);
        if (!iface_peer) {
            return XDP_DROP;
        }
        else {
            return bpf_redirect_map (&tx_peer, tx_port, 0);
        }

#else
        return XDP_DROP;

#endif
    }

#if BUILD_CPUMAP
    cpu_hash = tuple.src[0] + tuple.dst[0];
    cpu_hash += tuple.src[1] + tuple.dst[1];
    cpu_hash += tuple.src[2] + tuple.dst[2];
    cpu_hash += tuple.src[3] + tuple.dst[3];
    cpu_hash = SuperFastHash ((char *) & cpu_hash, 4, INITVAL);
    if (cpu_max && *cpu_max) {
        cpu_dest = cpu_hash % *cpu_max;
        cpu_selected = bpf_map_lookup_elem (& cpus_available, & cpu_dest);
        if (!cpu_selected)
            return XDP_ABORTED;
        cpu_dest = *cpu_selected;
        return bpf_redirect_map (&cpu_map, cpu_dest, 0);
    }
    else {
        return XDP_PASS;
    }

#else

#if RSS_QUEUE_NUMBERS
    __u32 xdp_hash = tuple.src[0] + tuple.dst[0];
    xdp_hash += tuple.src[1] + tuple.dst[1];
    xdp_hash += tuple.src[2] + tuple.dst[2];
    xdp_hash += tuple.src[3] + tuple.dst[3];
    xdp_hash = SuperFastHash ((char *) & xdp_hash, 4, INITVAL);
    ctx->rx_queue_index = xdp_hash % RSS_QUEUE_NUMBERS;

#endif
    return XDP_PASS;

#endif
}
</source>
<source file="/home/sayandes/opened_extraction/examples/suricata-master/ebpf/xdp_filter.c" funcheader="int SEC (\"xdp\") xdp_hashfilter (struct xdp_md *ctx)" startline="485" endline="552">
int SEC ("xdp") xdp_hashfilter (struct xdp_md *ctx)
{
    void *data_end = (void *) (long) ctx->data_end;
    void *data = (void *) (long) ctx->data;
    struct ethhdr *eth = data;
    __u16 h_proto;
    __u64 nh_off;
    __u16 vlan0 = 0;
    __u16 vlan1 = 0;

#if USE_GLOBAL_BYPASS
    int *iface_peer;
    char *g_switch = 0;
    char key0;
    int tx_port = 0;
    g_switch = bpf_map_lookup_elem (& global_bypass, & key0);
    if (g_switch && *g_switch) {
        iface_peer = bpf_map_lookup_elem (& tx_peer_int, & key0);
        if (!iface_peer) {
            return XDP_DROP;
        }
        else {
            return bpf_redirect_map (&tx_peer, tx_port, 0);
        }
    }

#endif
    nh_off = sizeof (*eth);
    if (data + nh_off > data_end)
        return XDP_PASS;
    h_proto = eth->h_proto;
    if (h_proto == __constant_htons (ETH_P_8021Q) || h_proto == __constant_htons (ETH_P_8021AD)) {
        struct vlan_hdr *vhdr;
        vhdr = data + nh_off;
        nh_off += sizeof (struct vlan_hdr);
        if (data + nh_off > data_end)
            return XDP_PASS;
        h_proto = vhdr->h_vlan_encapsulated_proto;

#if VLAN_TRACKING
        vlan0 = vhdr->h_vlan_TCI & 0x0fff;

#else
        vlan0 = 0;

#endif
    }
    if (h_proto == __constant_htons (ETH_P_8021Q) || h_proto == __constant_htons (ETH_P_8021AD)) {
        struct vlan_hdr *vhdr;
        vhdr = data + nh_off;
        nh_off += sizeof (struct vlan_hdr);
        if (data + nh_off > data_end)
            return XDP_PASS;
        h_proto = vhdr->h_vlan_encapsulated_proto;

#if VLAN_TRACKING
        vlan1 = vhdr->h_vlan_TCI & 0x0fff;

#else
        vlan1 = 0;

#endif
    }
    if (h_proto == __constant_htons (ETH_P_IP))
        return filter_ipv4 (ctx, data, nh_off, data_end, vlan0, vlan1);
    else if (h_proto == __constant_htons (ETH_P_IPV6))
        return filter_ipv6 (ctx, data, nh_off, data_end, vlan0, vlan1);
    return XDP_PASS;
}
</source>
</doc>
