<?xml version="1.0"?>
<doc>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline bool redirect_to_proxy (int verdict, enum ct_status status)" startline="157" endline="162">
static __always_inline bool redirect_to_proxy (int verdict, enum ct_status status)
{
    return is_defined (ENABLE_HOST_REDIRECT) && verdict > 0 && (status == CT_NEW || status == CT_ESTABLISHED || status == CT_REOPENED);
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int encode_custom_prog_meta (struct  __ctx_buff *ctx, int ret, __u32 identity)" startline="174" endline="189">
static __always_inline int encode_custom_prog_meta (struct  __ctx_buff *ctx, int ret, __u32 identity)
{
    __u32 custom_meta = 0;
    if ((ret & 0xff) != ret)
        return -1;
    custom_meta |= (__u32) (ret & 0xff) << 24;
    custom_meta |= (identity & 0xffffff);
    ctx_store_meta (ctx, CB_CUSTOM_CALLS, custom_meta);
    return 0;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int handle_ipv6_from_lxc (struct  __ctx_buff *ctx, __u32 *dst_id)" startline="214" endline="581">
static __always_inline int handle_ipv6_from_lxc (struct  __ctx_buff *ctx, __u32 *dst_id)
{
    struct ct_state ct_state_on_stack __maybe_unused, *ct_state, ct_state_new = {};
    struct ipv6_ct_tuple tuple_on_stack __maybe_unused, *tuple;

#ifdef ENABLE_ROUTING
    union macaddr router_mac = NODE_MAC;

#endif
    struct ct_buffer6 *ct_buffer;
    void *data, *data_end;
    struct ipv6hdr *ip6;
    int ret, verdict = 0, l4_off, hdrlen, zero = 0;
    struct trace_ctx trace = {
        .reason = TRACE_REASON_UNKNOWN,
        .monitor = 0,}
    ;
    __u32 __maybe_unused tunnel_endpoint = 0;
    __u8 __maybe_unused encrypt_key = 0;
    enum ct_status ct_status;
    bool hairpin_flow = false;
    __u8 policy_match_type = POLICY_MATCH_NONE;
    __u8 audited = 0;
    bool __maybe_unused dst_remote_ep = false;
    __u16 proxy_port = 0;
    bool from_l7lb = false;
    bool emit_policy_verdict = true;
    if (!revalidate_data (ctx, &data, &data_end, &ip6))
        return DROP_INVALID;
    if (1) {
        const union v6addr *daddr = (union v6addr *) &ip6->daddr;
        struct remote_endpoint_info *info;
        info = lookup_ip6_remote_endpoint (daddr);
        if (info && info->sec_label) {
            *dst_id = info->sec_label;
            tunnel_endpoint = info->tunnel_endpoint;
            encrypt_key = get_min_encrypt_key (info -> key);

#ifdef ENABLE_WIREGUARD
            if (info->tunnel_endpoint != 0 && !identity_is_node (info->sec_label))
                dst_remote_ep = true;

#endif /* ENABLE_WIREGUARD */
        }
        else {
            *dst_id = WORLD_ID;
        }
        cilium_dbg (ctx, info ? DBG_IP_ID_MAP_SUCCEED6 : DBG_IP_ID_MAP_FAILED6, daddr->p4, *dst_id);
    }

#ifdef ENABLE_PER_PACKET_LB

#if !defined(DEBUG) && defined(TUNNEL_MODE)
    if (!revalidate_data (ctx, &data, &data_end, &ip6))
        return DROP_INVALID;

#endif
    lb6_ctx_restore_state (ctx, &ct_state_new, &proxy_port);

#endif /* ENABLE_PER_PACKET_LB */
    ct_buffer = map_lookup_elem (& CT_TAIL_CALL_BUFFER6, & zero);
    if (!ct_buffer)
        return DROP_INVALID_TC_BUFFER;
    if (ct_buffer->tuple.saddr.d1 == 0 && ct_buffer->tuple.saddr.d2 == 0)
        return DROP_INVALID_TC_BUFFER;

#if HAVE_DIRECT_ACCESS_TO_MAP_VALUES
    tuple = (struct ipv6_ct_tuple *) &ct_buffer->tuple;
    ct_state = (struct ct_state *) &ct_buffer->ct_state;

#else
    memcpy (&tuple_on_stack, &ct_buffer->tuple, sizeof (tuple_on_stack));
    tuple = &tuple_on_stack;
    memcpy (&ct_state_on_stack, &ct_buffer->ct_state, sizeof (ct_state_on_stack));
    ct_state = &ct_state_on_stack;

#endif /* HAVE_DIRECT_ACCESS_TO_MAP_VALUES */
    trace.monitor = ct_buffer->monitor;
    ret = ct_buffer->ret;
    ct_status = (enum ct_status) ret;
    trace.reason = (enum trace_reason) ret;

#if defined(ENABLE_L7_LB)
    if (proxy_port > 0) {
        cilium_dbg3 (ctx, DBG_L7_LB, tuple->daddr.p4, tuple->saddr.p4, bpf_ntohs (proxy_port));
        verdict = proxy_port;
        emit_policy_verdict = false;
        goto skip_policy_enforcement;
    }

#endif /* ENABLE_L7_LB */
    if ((ct_status == CT_REPLY || ct_status == CT_RELATED) && ct_state->proxy_redirect) {
        return ctx_redirect_to_proxy6 (ctx, tuple, 0, false);
    }
    if (hairpin_flow) {
        emit_policy_verdict = false;
        goto skip_policy_enforcement;
    }
    verdict = policy_can_egress6 (ctx, tuple, SECLABEL, * dst_id, & policy_match_type, & audited);
    if (ct_status != CT_REPLY && ct_status != CT_RELATED && verdict < 0) {
        send_policy_verdict_notify (ctx, *dst_id, tuple->dport, tuple->nexthdr, POLICY_EGRESS, 1, verdict, policy_match_type, audited);
        return verdict;
    }
skip_policy_enforcement :

#if defined(ENABLE_L7_LB)
    from_l7lb = ctx_load_meta (ctx, CB_FROM_HOST) == FROM_HOST_L7_LB;

#endif
    switch (ct_status) {
    case CT_NEW :
        if (emit_policy_verdict)
            send_policy_verdict_notify (ctx, *dst_id, tuple->dport, tuple->nexthdr, POLICY_EGRESS, 1, verdict, policy_match_type, audited);
    ct_recreate6 :
        ct_state_new.src_sec_id = SECLABEL;
        ret = ct_create6 (get_ct_map6 (tuple), & CT_MAP_ANY6, tuple, ctx, CT_EGRESS, & ct_state_new, verdict > 0, from_l7lb);
        if (IS_ERR (ret))
            return ret;
        trace.monitor = TRACE_PAYLOAD_LEN;
        break;
    case CT_REOPENED :
        if (emit_policy_verdict)
            send_policy_verdict_notify (ctx, *dst_id, tuple->dport, tuple->nexthdr, POLICY_EGRESS, 1, verdict, policy_match_type, audited);
    case CT_ESTABLISHED :
        if (unlikely (ct_state->rev_nat_index != ct_state_new.rev_nat_index))
            goto ct_recreate6;
        break;
    case CT_RELATED :
    case CT_REPLY :
        policy_mark_skip (ctx);
        hdrlen = ipv6_hdrlen (ctx, & tuple -> nexthdr);
        if (hdrlen < 0)
            return hdrlen;
        l4_off = ETH_HLEN + hdrlen;

#ifdef ENABLE_NODEPORT

# ifdef ENABLE_DSR
        if (ct_state->dsr) {
            ret = xlate_dsr_v6 (ctx, tuple, l4_off);
            if (ret != 0)
                return ret;
        }
        else

# endif /* ENABLE_DSR */
            if (ct_state->node_port) {
                send_trace_notify (ctx, TRACE_TO_NETWORK, SECLABEL, *dst_id, 0, 0, trace.reason, trace.monitor);
                ctx->tc_index |= TC_INDEX_F_SKIP_RECIRCULATION;
                ep_tail_call (ctx, CILIUM_CALL_IPV6_NODEPORT_REVNAT);
                return DROP_MISSED_TAIL_CALL;
            }

#endif /* ENABLE_NODEPORT */
        if (ct_state->rev_nat_index) {
            struct csum_offset csum_off = {}
            ;
            csum_l4_offset_and_flags (tuple->nexthdr, &csum_off);
            ret = lb6_rev_nat (ctx, l4_off, & csum_off, ct_state -> rev_nat_index, tuple, 0);
            if (IS_ERR (ret))
                return ret;
            policy_mark_skip (ctx);
        }
        break;
    default :
        return DROP_UNKNOWN_CT;
    }
    hairpin_flow |= ct_state->loopback;
    if (!from_l7lb && redirect_to_proxy (verdict, ct_status)) {
        proxy_port = (__u16) verdict;
        send_trace_notify (ctx, TRACE_TO_PROXY, SECLABEL, 0, bpf_ntohs (proxy_port), 0, trace.reason, trace.monitor);
        return ctx_redirect_to_proxy6 (ctx, tuple, proxy_port, false);
    }
    if (!revalidate_data (ctx, &data, &data_end, &ip6))
        return DROP_INVALID;
    if (is_defined (ENABLE_ROUTING) || hairpin_flow) {
        struct endpoint_info *ep;
        ep = lookup_ip6_endpoint (ip6);
        if (ep) {

#ifdef ENABLE_ROUTING
            if (ep->flags & ENDPOINT_F_HOST) {

#ifdef HOST_IFINDEX
                goto to_host;

#else
                return DROP_HOST_UNREACHABLE;

#endif
            }

#endif /* ENABLE_ROUTING */
            policy_clear_mark (ctx);
            return ipv6_local_delivery (ctx, ETH_HLEN, SECLABEL, ep, METRIC_EGRESS, from_l7lb);
        }
    }

#if defined(ENABLE_HOST_FIREWALL) && !defined(ENABLE_ROUTING)
    if (*dst_id == HOST_ID) {
        ctx_store_meta (ctx, CB_FROM_HOST, 0);
        tail_call_static (ctx, &POLICY_CALL_MAP, HOST_EP_ID);
        return DROP_MISSED_TAIL_CALL;
    }

#endif /* ENABLE_HOST_FIREWALL && !ENABLE_ROUTING */

#ifdef TUNNEL_MODE

# ifdef ENABLE_WIREGUARD
    if (!dst_remote_ep)

# endif /* ENABLE_WIREGUARD */
        {
            struct endpoint_key key = {}
            ;
            union v6addr *daddr = (union v6addr *) &ip6->daddr;
            key.ip6.p1 = daddr->p1;
            key.ip6.p2 = daddr->p2;
            key.ip6.p3 = daddr->p3;
            key.family = ENDPOINT_KEY_IPV6;
            ret = encap_and_redirect_lxc (ctx, tunnel_endpoint, encrypt_key, & key, SECLABEL, & trace);
            if (ret == IPSEC_ENDPOINT)
                goto encrypt_to_stack;
            else if (ret != DROP_NO_TUNNEL_ENDPOINT)
                return ret;
        }

#endif
    if (is_defined (ENABLE_HOST_ROUTING))
        return redirect_direct_v6 (ctx, ETH_HLEN, ip6);
    goto pass_to_stack;

#ifdef ENABLE_ROUTING
to_host :
    if (is_defined (ENABLE_HOST_FIREWALL) && *dst_id == HOST_ID) {
        send_trace_notify (ctx, TRACE_TO_HOST, SECLABEL, HOST_ID, 0, HOST_IFINDEX, trace.reason, trace.monitor);
        return ctx_redirect (ctx, HOST_IFINDEX, BPF_F_INGRESS);
    }

#endif
pass_to_stack :

#ifdef ENABLE_ROUTING
    ret = ipv6_l3 (ctx, ETH_HLEN, NULL, (__u8 *) & router_mac.addr, METRIC_EGRESS);
    if (unlikely (ret != CTX_ACT_OK))
        return ret;

#endif
    if (ipv6_store_flowlabel (ctx, ETH_HLEN, SECLABEL_NB) < 0)
        return DROP_WRITE_ERROR;

#ifdef ENABLE_WIREGUARD
    if (dst_remote_ep)
        set_encrypt_mark (ctx);
    else

#elif !defined(TUNNEL_MODE)

# ifdef ENABLE_IPSEC
        if (encrypt_key && tunnel_endpoint) {
            set_encrypt_key_mark (ctx, encrypt_key);

#  ifdef IP_POOLS
            set_encrypt_dip (ctx, tunnel_endpoint);

#  endif /* IP_POOLS */

#  ifdef ENABLE_IDENTITY_MARK
            set_identity_mark (ctx, SECLABEL);

#  endif /* ENABLE_IDENTITY_MARK */
        }
        else

# endif /* ENABLE_IPSEC */

#endif /* ENABLE_WIREGUARD */
            {

#ifdef ENABLE_IDENTITY_MARK
                ctx->mark |= MARK_MAGIC_IDENTITY;
                set_identity_mark (ctx, SECLABEL);

#endif
            }

#ifdef TUNNEL_MODE
encrypt_to_stack :

#endif
    send_trace_notify (ctx, TRACE_TO_STACK, SECLABEL, *dst_id, 0, 0, trace.reason, trace.monitor);
    cilium_dbg_capture (ctx, DBG_CAPTURE_DELIVERY, 0);
    return CTX_ACT_OK;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_handle_ipv6_cont (struct  __ctx_buff *ctx)" startline="584" endline="603">
int tail_handle_ipv6_cont (struct  __ctx_buff *ctx)
{
    __u32 dst_id = 0;
    int ret = handle_ipv6_from_lxc (ctx, & dst_id);
    if (IS_ERR (ret))
        return send_drop_notify (ctx, SECLABEL, dst_id, 0, ret, CTX_ACT_DROP, METRIC_EGRESS);

#ifdef ENABLE_CUSTOM_CALLS
    if (!encode_custom_prog_meta (ctx, ret, dst_id)) {
        tail_call_static (ctx, &CUSTOM_CALLS_MAP, CUSTOM_CALLS_IDX_IPV6_EGRESS);
        update_metrics (ctx_full_len (ctx), METRIC_EGRESS, REASON_MISSED_CUSTOM_CALL);
    }

#endif
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int __tail_handle_ipv6 (struct  __ctx_buff *ctx)" startline="609" endline="694">
static __always_inline int __tail_handle_ipv6 (struct  __ctx_buff *ctx)
{
    void *data, *data_end;
    struct ipv6hdr *ip6;
    int ret;
    if (!revalidate_data_pull (ctx, &data, &data_end, &ip6))
        return DROP_INVALID;
    if (unlikely (ip6->nexthdr == IPPROTO_ICMPV6)) {
        if (data + sizeof (*ip6) + ETH_HLEN + sizeof (struct icmp6hdr) > data_end)
            return DROP_INVALID;
        ret = icmp6_handle (ctx, ETH_HLEN, ip6, METRIC_EGRESS);
        if (IS_ERR (ret))
            return ret;
    }
    if (unlikely (!is_valid_lxc_src_ip (ip6)))
        return DROP_INVALID_SIP;

#ifdef ENABLE_PER_PACKET_LB
    {
        struct ipv6_ct_tuple tuple = {}
        ;
        struct csum_offset csum_off = {}
        ;
        struct ct_state ct_state_new = {}
        ;
        struct lb6_service *svc;
        struct lb6_key key = {}
        ;
        __u16 proxy_port = 0;
        int l4_off, hdrlen;
        tuple.nexthdr = ip6->nexthdr;
        ipv6_addr_copy (&tuple.daddr, (union v6addr *) &ip6->daddr);
        ipv6_addr_copy (&tuple.saddr, (union v6addr *) &ip6->saddr);
        hdrlen = ipv6_hdrlen (ctx, & tuple.nexthdr);
        if (hdrlen < 0)
            return hdrlen;
        l4_off = ETH_HLEN + hdrlen;
        ret = lb6_extract_key (ctx, & tuple, l4_off, & key, & csum_off, CT_EGRESS);
        if (IS_ERR (ret)) {
            if (ret == DROP_NO_SERVICE || ret == DROP_UNKNOWN_L4)
                goto skip_service_lookup;
            else
                return ret;
        }
        svc = lb6_lookup_service (& key, is_defined (ENABLE_NODEPORT));
        if (svc) {

#if defined(ENABLE_L7_LB)
            if (lb6_svc_is_l7loadbalancer (svc)) {
                proxy_port = (__u16) svc->l7_lb_proxy_port;
                goto skip_service_lookup;
            }

#endif /* ENABLE_L7_LB */
            ret = lb6_local (get_ct_map6 (& tuple), ctx, ETH_HLEN, l4_off, & csum_off, & key, & tuple, svc, & ct_state_new, false);
            if (IS_ERR (ret))
                return ret;
        }
    skip_service_lookup :
        lb6_ctx_store_state (ctx, &ct_state_new, proxy_port);
    }

#endif /* ENABLE_PER_PACKET_LB */
    invoke_tailcall_if (is_defined (ENABLE_PER_PACKET_LB), CILIUM_CALL_IPV6_CT_EGRESS, tail_ipv6_ct_egress);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_handle_ipv6 (struct  __ctx_buff *ctx)" startline="697" endline="705">
int tail_handle_ipv6 (struct  __ctx_buff *ctx)
{
    int ret = __tail_handle_ipv6 (ctx);
    if (IS_ERR (ret))
        return send_drop_notify_error (ctx, SECLABEL, ret, CTX_ACT_DROP, METRIC_EGRESS);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int handle_ipv4_from_lxc (struct  __ctx_buff *ctx, __u32 *dst_id)" startline="728" endline="1157">
static __always_inline int handle_ipv4_from_lxc (struct  __ctx_buff *ctx, __u32 *dst_id)
{
    struct ct_state ct_state_on_stack __maybe_unused, *ct_state, ct_state_new = {};
    struct ipv4_ct_tuple tuple_on_stack __maybe_unused, *tuple;

#ifdef ENABLE_ROUTING
    union macaddr router_mac = NODE_MAC;

#endif
    void *data, *data_end;
    struct iphdr *ip4;
    int ret, verdict = 0, l4_off;
    struct trace_ctx trace = {
        .reason = TRACE_REASON_UNKNOWN,
        .monitor = 0,}
    ;
    __u32 __maybe_unused tunnel_endpoint = 0, zero = 0;
    __u8 __maybe_unused encrypt_key = 0;
    bool hairpin_flow = false;
    __u8 policy_match_type = POLICY_MATCH_NONE;
    struct ct_buffer4 *ct_buffer;
    __u8 audited = 0;
    bool has_l4_header = false;
    bool __maybe_unused dst_remote_ep = false;
    enum ct_status ct_status;
    __u16 proxy_port = 0;
    bool from_l7lb = false;
    bool emit_policy_verdict = true;
    if (!revalidate_data (ctx, &data, &data_end, &ip4))
        return DROP_INVALID;
    has_l4_header = ipv4_has_l4_header (ip4);
    if (1) {
        struct remote_endpoint_info *info;
        info = lookup_ip4_remote_endpoint (ip4 -> daddr);
        if (info && info->sec_label) {
            *dst_id = info->sec_label;
            tunnel_endpoint = info->tunnel_endpoint;
            encrypt_key = get_min_encrypt_key (info -> key);

#ifdef ENABLE_WIREGUARD
            if (info->tunnel_endpoint != 0 && !identity_is_node (info->sec_label))
                dst_remote_ep = true;

#endif /* ENABLE_WIREGUARD */
        }
        else {
            *dst_id = WORLD_ID;
        }
        cilium_dbg (ctx, info ? DBG_IP_ID_MAP_SUCCEED4 : DBG_IP_ID_MAP_FAILED4, ip4->daddr, *dst_id);
    }

#ifdef ENABLE_PER_PACKET_LB
    lb4_ctx_restore_state (ctx, &ct_state_new, ip4->daddr, &proxy_port);
    hairpin_flow = ct_state_new.loopback;

#endif /* ENABLE_PER_PACKET_LB */
    l4_off = ETH_HLEN + ipv4_hdrlen (ip4);
    ct_buffer = map_lookup_elem (& CT_TAIL_CALL_BUFFER4, & zero);
    if (!ct_buffer)
        return DROP_INVALID_TC_BUFFER;
    if (ct_buffer->tuple.saddr == 0)
        return DROP_INVALID_TC_BUFFER;

#if HAVE_DIRECT_ACCESS_TO_MAP_VALUES
    tuple = (struct ipv4_ct_tuple *) &ct_buffer->tuple;
    ct_state = (struct ct_state *) &ct_buffer->ct_state;

#else
    memcpy (&tuple_on_stack, &ct_buffer->tuple, sizeof (tuple_on_stack));
    tuple = &tuple_on_stack;
    memcpy (&ct_state_on_stack, &ct_buffer->ct_state, sizeof (ct_state_on_stack));
    ct_state = &ct_state_on_stack;

#endif /* HAVE_DIRECT_ACCESS_TO_MAP_VALUES */
    trace.monitor = ct_buffer->monitor;
    ret = ct_buffer->ret;
    ct_status = (enum ct_status) ret;
    trace.reason = (enum trace_reason) ret;

#if defined(ENABLE_L7_LB)
    if (proxy_port > 0) {
        cilium_dbg3 (ctx, DBG_L7_LB, tuple->daddr, tuple->saddr, bpf_ntohs (proxy_port));
        verdict = proxy_port;
        emit_policy_verdict = false;
        goto skip_policy_enforcement;
    }

#endif /* ENABLE_L7_LB */
    if ((ct_status == CT_REPLY || ct_status == CT_RELATED) && ct_state->proxy_redirect) {
        return ctx_redirect_to_proxy4 (ctx, tuple, 0, false);
    }
    if (hairpin_flow) {
        emit_policy_verdict = false;
        goto skip_policy_enforcement;
    }
    verdict = policy_can_egress4 (ctx, tuple, SECLABEL, * dst_id, & policy_match_type, & audited);
    if (ct_status != CT_REPLY && ct_status != CT_RELATED && verdict < 0) {
        send_policy_verdict_notify (ctx, *dst_id, tuple->dport, tuple->nexthdr, POLICY_EGRESS, 0, verdict, policy_match_type, audited);
        return verdict;
    }
skip_policy_enforcement :

#if defined(ENABLE_L7_LB)
    from_l7lb = ctx_load_meta (ctx, CB_FROM_HOST) == FROM_HOST_L7_LB;

#endif
    switch (ct_status) {
    case CT_NEW :
        if (emit_policy_verdict)
            send_policy_verdict_notify (ctx, *dst_id, tuple->dport, tuple->nexthdr, POLICY_EGRESS, 0, verdict, policy_match_type, audited);
    ct_recreate4 :
        ct_state_new.src_sec_id = SECLABEL;
        ret = ct_create4 (get_ct_map4 (tuple), & CT_MAP_ANY4, tuple, ctx, CT_EGRESS, & ct_state_new, verdict > 0, from_l7lb);
        if (IS_ERR (ret))
            return ret;
        break;
    case CT_REOPENED :
        if (emit_policy_verdict)
            send_policy_verdict_notify (ctx, *dst_id, tuple->dport, tuple->nexthdr, POLICY_EGRESS, 0, verdict, policy_match_type, audited);
    case CT_ESTABLISHED :
        if (unlikely (ct_state->rev_nat_index != ct_state_new.rev_nat_index))
            goto ct_recreate4;
        break;
    case CT_RELATED :
    case CT_REPLY :
        policy_mark_skip (ctx);

#ifdef ENABLE_NODEPORT

# ifdef ENABLE_DSR
        if (ct_state->dsr) {
            ret = xlate_dsr_v4 (ctx, tuple, l4_off, has_l4_header);
            if (ret != 0)
                return ret;
        }
        else

# endif /* ENABLE_DSR */
            if (ct_state->node_port) {
                send_trace_notify (ctx, TRACE_TO_NETWORK, SECLABEL, *dst_id, 0, 0, trace.reason, trace.monitor);
                ctx->tc_index |= TC_INDEX_F_SKIP_RECIRCULATION;
                ep_tail_call (ctx, CILIUM_CALL_IPV4_NODEPORT_REVNAT);
                return DROP_MISSED_TAIL_CALL;
            }

#endif /* ENABLE_NODEPORT */
        if (ct_state->rev_nat_index) {
            struct csum_offset csum_off = {}
            ;
            csum_l4_offset_and_flags (tuple->nexthdr, &csum_off);
            ret = lb4_rev_nat (ctx, ETH_HLEN, l4_off, & csum_off, ct_state, tuple, 0, has_l4_header);
            if (IS_ERR (ret))
                return ret;
        }
        break;
    default :
        return DROP_UNKNOWN_CT;
    }
    hairpin_flow |= ct_state->loopback;
    if (!from_l7lb && redirect_to_proxy (verdict, ct_status)) {
        proxy_port = (__u16) verdict;
        send_trace_notify (ctx, TRACE_TO_PROXY, SECLABEL, 0, bpf_ntohs (proxy_port), 0, trace.reason, trace.monitor);
        return ctx_redirect_to_proxy4 (ctx, tuple, proxy_port, false);
    }
    if (!revalidate_data (ctx, &data, &data_end, &ip4))
        return DROP_INVALID;
    if (is_defined (ENABLE_ROUTING) || hairpin_flow) {
        struct endpoint_info *ep;
        ep = lookup_ip4_endpoint (ip4);
        if (ep) {

#ifdef ENABLE_ROUTING
            if (ep->flags & ENDPOINT_F_HOST) {

#ifdef HOST_IFINDEX
                goto to_host;

#else
                return DROP_HOST_UNREACHABLE;

#endif
            }

#endif /* ENABLE_ROUTING */
            policy_clear_mark (ctx);
            return ipv4_local_delivery (ctx, ETH_HLEN, SECLABEL, ip4, ep, METRIC_EGRESS, from_l7lb);
        }
    }

#if defined(ENABLE_HOST_FIREWALL) && !defined(ENABLE_ROUTING)
    if (*dst_id == HOST_ID) {
        ctx_store_meta (ctx, CB_FROM_HOST, 0);
        tail_call_static (ctx, &POLICY_CALL_MAP, HOST_EP_ID);
        return DROP_MISSED_TAIL_CALL;
    }

#endif /* ENABLE_HOST_FIREWALL && !ENABLE_ROUTING */

#ifdef ENABLE_EGRESS_GATEWAY
    {
        struct egress_gw_policy_entry *egress_gw_policy;
        struct endpoint_info *gateway_node_ep;
        struct endpoint_key key = {}
        ;
        if (identity_is_cluster (*dst_id))
            goto skip_egress_gateway;
        if (ct_status == CT_REPLY || ct_status == CT_RELATED)
            goto skip_egress_gateway;
        egress_gw_policy = lookup_ip4_egress_gw_policy (ip4 -> saddr, ip4 -> daddr);
        if (!egress_gw_policy)
            goto skip_egress_gateway;
        gateway_node_ep = __lookup_ip4_endpoint (egress_gw_policy -> gateway_ip);
        if (gateway_node_ep && (gateway_node_ep->flags & ENDPOINT_F_HOST))
            goto skip_egress_gateway;
        ret = encap_and_redirect_lxc (ctx, egress_gw_policy -> gateway_ip, encrypt_key, & key, SECLABEL, & trace);
        if (ret == IPSEC_ENDPOINT)
            goto encrypt_to_stack;
        else
            return ret;
    }
skip_egress_gateway :

#endif

#if defined(ENABLE_VTEP)
    {
        struct vtep_key vkey = {}
        ;
        struct vtep_value *vtep;
        vkey.vtep_ip = ip4->daddr & VTEP_MASK;
        vtep = map_lookup_elem (& VTEP_MAP, & vkey);
        if (!vtep)
            goto skip_vtep;
        if (vtep->vtep_mac && vtep->tunnel_endpoint) {
            if (eth_store_daddr (ctx, (__u8 *) &vtep->vtep_mac, 0) < 0)
                return DROP_WRITE_ERROR;
            return __encap_and_redirect_with_nodeid (ctx, vtep->tunnel_endpoint, SECLABEL, WORLD_ID, &trace);
        }
    }
skip_vtep :

#endif

#ifdef TUNNEL_MODE

# ifdef ENABLE_WIREGUARD
    if (!dst_remote_ep)

# endif /* ENABLE_WIREGUARD */
        {
            struct endpoint_key key = {}
            ;
            key.ip4 = ip4->daddr & IPV4_MASK;
            key.family = ENDPOINT_KEY_IPV4;
            ret = encap_and_redirect_lxc (ctx, tunnel_endpoint, encrypt_key, & key, SECLABEL, & trace);
            if (ret == DROP_NO_TUNNEL_ENDPOINT)
                goto pass_to_stack;
            else if (ret == IPSEC_ENDPOINT)
                goto encrypt_to_stack;
            else
                return ret;
        }

#endif /* TUNNEL_MODE */
    if (is_defined (ENABLE_HOST_ROUTING))
        return redirect_direct_v4 (ctx, ETH_HLEN, ip4);
    goto pass_to_stack;

#ifdef ENABLE_ROUTING
to_host :
    if (is_defined (ENABLE_HOST_FIREWALL) && *dst_id == HOST_ID) {
        send_trace_notify (ctx, TRACE_TO_HOST, SECLABEL, HOST_ID, 0, HOST_IFINDEX, trace.reason, trace.monitor);
        return ctx_redirect (ctx, HOST_IFINDEX, BPF_F_INGRESS);
    }

#endif
pass_to_stack :

#ifdef ENABLE_ROUTING
    ret = ipv4_l3 (ctx, ETH_HLEN, NULL, (__u8 *) & router_mac.addr, ip4);
    if (unlikely (ret != CTX_ACT_OK))
        return ret;

#endif

#ifdef ENABLE_WIREGUARD
    if (dst_remote_ep)
        set_encrypt_mark (ctx);
    else

#elif !defined(TUNNEL_MODE)

# ifdef ENABLE_IPSEC
        if (encrypt_key && tunnel_endpoint) {
            set_encrypt_key_mark (ctx, encrypt_key);

#  ifdef IP_POOLS
            set_encrypt_dip (ctx, tunnel_endpoint);

#  endif /* IP_POOLS */

#  ifdef ENABLE_IDENTITY_MARK
            set_identity_mark (ctx, SECLABEL);

#  endif
        }
        else

# endif /* ENABLE_IPSEC */

#endif /* ENABLE_WIREGUARD */
            {

#ifdef ENABLE_IDENTITY_MARK
                ctx->mark |= MARK_MAGIC_IDENTITY;
                set_identity_mark (ctx, SECLABEL);

#endif
            }

#if defined(TUNNEL_MODE) || defined(ENABLE_EGRESS_GATEWAY)
encrypt_to_stack :

#endif
    send_trace_notify (ctx, TRACE_TO_STACK, SECLABEL, *dst_id, 0, 0, trace.reason, trace.monitor);
    cilium_dbg_capture (ctx, DBG_CAPTURE_DELIVERY, 0);
    return CTX_ACT_OK;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_handle_ipv4_cont (struct  __ctx_buff *ctx)" startline="1160" endline="1179">
int tail_handle_ipv4_cont (struct  __ctx_buff *ctx)
{
    __u32 dst_id = 0;
    int ret = handle_ipv4_from_lxc (ctx, & dst_id);
    if (IS_ERR (ret))
        return send_drop_notify (ctx, SECLABEL, dst_id, 0, ret, CTX_ACT_DROP, METRIC_EGRESS);

#ifdef ENABLE_CUSTOM_CALLS
    if (!encode_custom_prog_meta (ctx, ret, dst_id)) {
        tail_call_static (ctx, &CUSTOM_CALLS_MAP, CUSTOM_CALLS_IDX_IPV4_EGRESS);
        update_metrics (ctx_full_len (ctx), METRIC_EGRESS, REASON_MISSED_CUSTOM_CALL);
    }

#endif
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int __tail_handle_ipv4 (struct  __ctx_buff *ctx)" startline="1185" endline="1256">
static __always_inline int __tail_handle_ipv4 (struct  __ctx_buff *ctx)
{
    void *data, *data_end;
    struct iphdr *ip4;
    int ret;
    if (!revalidate_data_pull (ctx, &data, &data_end, &ip4))
        return DROP_INVALID;

#ifndef ENABLE_IPV4_FRAGMENTS
    if (ipv4_is_fragment (ip4))
        return DROP_FRAG_NOSUPPORT;

#endif
    if (unlikely (!is_valid_lxc_src_ipv4 (ip4)))
        return DROP_INVALID_SIP;

#ifdef ENABLE_PER_PACKET_LB
    {
        struct ipv4_ct_tuple tuple = {}
        ;
        struct csum_offset csum_off = {}
        ;
        struct ct_state ct_state_new = {}
        ;
        bool has_l4_header;
        struct lb4_service *svc;
        struct lb4_key key = {}
        ;
        __u16 proxy_port = 0;
        int l4_off;
        has_l4_header = ipv4_has_l4_header (ip4);
        tuple.nexthdr = ip4->protocol;
        tuple.daddr = ip4->daddr;
        tuple.saddr = ip4->saddr;
        l4_off = ETH_HLEN + ipv4_hdrlen (ip4);
        ret = lb4_extract_key (ctx, ip4, l4_off, & key, & csum_off, CT_EGRESS);
        if (IS_ERR (ret)) {
            if (ret == DROP_NO_SERVICE || ret == DROP_UNKNOWN_L4)
                goto skip_service_lookup;
            else
                return ret;
        }
        svc = lb4_lookup_service (& key, is_defined (ENABLE_NODEPORT));
        if (svc) {

#if defined(ENABLE_L7_LB)
            if (lb4_svc_is_l7loadbalancer (svc)) {
                proxy_port = (__u16) svc->l7_lb_proxy_port;
                goto skip_service_lookup;
            }

#endif /* ENABLE_L7_LB */
            ret = lb4_local (get_ct_map4 (& tuple), ctx, ETH_HLEN, l4_off, & csum_off, & key, & tuple, svc, & ct_state_new, ip4 -> saddr, has_l4_header, false);
            if (IS_ERR (ret))
                return ret;
        }
    skip_service_lookup :
        lb4_ctx_store_state (ctx, &ct_state_new, proxy_port);
    }

#endif /* ENABLE_PER_PACKET_LB */
    invoke_tailcall_if (is_defined (ENABLE_PER_PACKET_LB), CILIUM_CALL_IPV4_CT_EGRESS, tail_ipv4_ct_egress);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_handle_ipv4 (struct  __ctx_buff *ctx)" startline="1259" endline="1267">
int tail_handle_ipv4 (struct  __ctx_buff *ctx)
{
    int ret = __tail_handle_ipv4 (ctx);
    if (IS_ERR (ret))
        return send_drop_notify_error (ctx, SECLABEL, ret, CTX_ACT_DROP, METRIC_EGRESS);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_handle_arp (struct  __ctx_buff *ctx)" startline="1275" endline="1300">
int tail_handle_arp (struct  __ctx_buff *ctx)
{
    union macaddr mac = NODE_MAC;
    union macaddr smac;
    __be32 sip;
    __be32 tip;
    if (!arp_validate (ctx, &mac, &smac, &sip, &tip))
        return CTX_ACT_OK;
    if (tip == LXC_IPV4)
        return CTX_ACT_OK;
    return arp_respond (ctx, &mac, tip, &smac, sip, 0);
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int handle_xgress (struct  __ctx_buff *ctx)" startline="1308" endline="1358">
int handle_xgress (struct  __ctx_buff *ctx)
{
    __u16 proto;
    int ret;
    bpf_clear_meta (ctx);
    reset_queue_mapping (ctx);
    send_trace_notify (ctx, TRACE_FROM_LXC, SECLABEL, 0, 0, 0, TRACE_REASON_UNKNOWN, TRACE_PAYLOAD_LEN);
    if (!validate_ethertype (ctx, &proto)) {
        ret = DROP_UNSUPPORTED_L2;
        goto out;
    }
    switch (proto) {

#ifdef ENABLE_IPV6
    case bpf_htons (ETH_P_IPV6) :
        edt_set_aggregate (ctx, LXC_ID);
        ep_tail_call (ctx, CILIUM_CALL_IPV6_FROM_LXC);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#endif /* ENABLE_IPV6 */

#ifdef ENABLE_IPV4
    case bpf_htons (ETH_P_IP) :
        edt_set_aggregate (ctx, LXC_ID);
        ep_tail_call (ctx, CILIUM_CALL_IPV4_FROM_LXC);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#ifdef ENABLE_ARP_PASSTHROUGH
    case bpf_htons (ETH_P_ARP) :
        ret = CTX_ACT_OK;
        break;

#elif defined(ENABLE_ARP_RESPONDER)
    case bpf_htons (ETH_P_ARP) :
        ep_tail_call (ctx, CILIUM_CALL_ARP);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#endif /* ENABLE_ARP_RESPONDER */

#endif /* ENABLE_IPV4 */
    default :
        ret = DROP_UNKNOWN_L3;
    }
out :
    if (IS_ERR (ret))
        return send_drop_notify (ctx, SECLABEL, 0, 0, ret, CTX_ACT_DROP, METRIC_EGRESS);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int ipv6_policy (struct  __ctx_buff *ctx, int ifindex, __u32 src_label, enum ct_status *ct_status, struct ipv6_ct_tuple *tuple_out, __u16 *proxy_port, bool from_host __maybe_unused)" startline="1361" endline="1536">
static __always_inline int ipv6_policy (struct  __ctx_buff *ctx, int ifindex, __u32 src_label, enum ct_status *ct_status, struct ipv6_ct_tuple *tuple_out, __u16 *proxy_port, bool from_host __maybe_unused)
{
    struct ct_state ct_state_on_stack __maybe_unused, *ct_state, ct_state_new = {};
    struct ipv6_ct_tuple tuple_on_stack __maybe_unused, *tuple;
    int ret, verdict, hdrlen, zero = 0;
    struct ct_buffer6 *ct_buffer;
    void *data, *data_end;
    struct ipv6hdr *ip6;
    bool skip_ingress_proxy = false;
    enum trace_reason reason;
    union v6addr orig_sip;
    __u32 monitor = 0;
    __u8 policy_match_type = POLICY_MATCH_NONE;
    __u8 audited = 0;
    bool emit_policy_verdict = true;
    if (!revalidate_data (ctx, &data, &data_end, &ip6))
        return DROP_INVALID;
    policy_clear_mark (ctx);
    ipv6_addr_copy (&orig_sip, (union v6addr *) &ip6->saddr);
    skip_ingress_proxy = tc_index_skip_ingress_proxy (ctx);
    ct_buffer = map_lookup_elem (& CT_TAIL_CALL_BUFFER6, & zero);
    if (!ct_buffer)
        return DROP_INVALID_TC_BUFFER;
    if (ct_buffer->tuple.saddr.d1 == 0 && ct_buffer->tuple.saddr.d2 == 0)
        return DROP_INVALID_TC_BUFFER;

#if HAVE_DIRECT_ACCESS_TO_MAP_VALUES
    tuple = (struct ipv6_ct_tuple *) &ct_buffer->tuple;
    ct_state = (struct ct_state *) &ct_buffer->ct_state;

#else
    memcpy (&tuple_on_stack, &ct_buffer->tuple, sizeof (tuple_on_stack));
    tuple = &tuple_on_stack;
    memcpy (&ct_state_on_stack, &ct_buffer->ct_state, sizeof (ct_state_on_stack));
    ct_state = &ct_state_on_stack;

#endif /* HAVE_DIRECT_ACCESS_TO_MAP_VALUES */
    monitor = ct_buffer->monitor;
    ret = ct_buffer->ret;
    *ct_status = (enum ct_status) ret;
    if ((ret == CT_REPLY || ret == CT_RELATED) && (ct_state_is_from_l7lb (ct_state) || (ct_state->proxy_redirect && !tc_index_skip_egress_proxy (ctx)))) {
        send_trace_notify6 (ctx, TRACE_TO_PROXY, src_label, SECLABEL, &orig_sip, 0, ifindex, (enum trace_reason) ret, monitor);
        if (tuple_out)
            memcpy (tuple_out, tuple, sizeof (*tuple));
        return POLICY_ACT_PROXY_REDIRECT;
    }
    if (unlikely (ct_state->rev_nat_index)) {
        struct csum_offset csum_off = {}
        ;
        int ret2, l4_off;
        hdrlen = ipv6_hdrlen (ctx, & tuple -> nexthdr);
        if (hdrlen < 0)
            return hdrlen;
        l4_off = ETH_HLEN + hdrlen;
        csum_l4_offset_and_flags (tuple->nexthdr, &csum_off);
        ret2 = lb6_rev_nat (ctx, l4_off, & csum_off, ct_state -> rev_nat_index, tuple, 0);
        if (IS_ERR (ret2))
            return ret2;
    }
    verdict = policy_can_access_ingress (ctx, src_label, SECLABEL, tuple -> dport, tuple -> nexthdr, false, & policy_match_type, & audited);
    if (ret != CT_REPLY && ret != CT_RELATED && verdict < 0) {
        send_policy_verdict_notify (ctx, src_label, tuple->dport, tuple->nexthdr, POLICY_INGRESS, 1, verdict, policy_match_type, audited);
        return verdict;
    }
    if (skip_ingress_proxy) {
        verdict = 0;
        emit_policy_verdict = false;
    }
    if (emit_policy_verdict && (ret == CT_NEW || ret == CT_REOPENED)) {
        send_policy_verdict_notify (ctx, src_label, tuple->dport, tuple->nexthdr, POLICY_INGRESS, 1, verdict, policy_match_type, audited);
    }

#ifdef ENABLE_NODEPORT
    if (ret == CT_NEW || ret == CT_REOPENED) {
        bool dsr = false;

# ifdef ENABLE_DSR
        int ret2;
        ret2 = handle_dsr_v6 (ctx, & dsr);
        if (ret2 != 0)
            return ret2;
        ct_state_new.dsr = dsr;
        if (ret == CT_REOPENED && ct_state->dsr != dsr)
            ct_update6_dsr (get_ct_map6 (tuple), tuple, dsr);

# endif /* ENABLE_DSR */
        if (!dsr) {
            bool node_port = ct_has_nodeport_egress_entry6 (get_ct_map6 (tuple), tuple);
            ct_state_new.node_port = node_port;
            if (ret == CT_REOPENED && ct_state->node_port != node_port)
                ct_update_nodeport (get_ct_map6 (tuple), tuple, node_port);
        }
    }

#endif /* ENABLE_NODEPORT */
    if (ret == CT_NEW) {
        ct_state_new.src_sec_id = src_label;
        ret = ct_create6 (get_ct_map6 (tuple), & CT_MAP_ANY6, tuple, ctx, CT_INGRESS, & ct_state_new, verdict > 0, false);
        if (IS_ERR (ret))
            return ret;
    }
    if (!revalidate_data (ctx, &data, &data_end, &ip6))
        return DROP_INVALID;
    reason = (enum trace_reason) *ct_status;
    if (redirect_to_proxy (verdict, *ct_status)) {
        *proxy_port = (__u16) verdict;
        send_trace_notify6 (ctx, TRACE_TO_PROXY, src_label, SECLABEL, &orig_sip, bpf_ntohs (*proxy_port), ifindex, reason, monitor);
        if (tuple_out)
            memcpy (tuple_out, tuple, sizeof (*tuple));
        return POLICY_ACT_PROXY_REDIRECT;
    }
    send_trace_notify6 (ctx, TRACE_TO_LXC, src_label, SECLABEL, &orig_sip, LXC_ID, ifindex, reason, monitor);

#if !defined(ENABLE_ROUTING) && defined(TUNNEL_MODE) && !defined(ENABLE_NODEPORT)
    ctx_change_type (ctx, PACKET_HOST);

#else
    ifindex = ctx_load_meta (ctx, CB_IFINDEX);
    if (ifindex)
        return redirect_ep (ctx, ifindex, from_host);

#endif /* !ENABLE_ROUTING && TUNNEL_MODE && !ENABLE_NODEPORT */
    return CTX_ACT_OK;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_ipv6_policy (struct  __ctx_buff *ctx)" startline="1540" endline="1581">
int tail_ipv6_policy (struct  __ctx_buff *ctx)
{
    struct ipv6_ct_tuple tuple = {}
    ;
    int ret, ifindex = ctx_load_meta (ctx, CB_IFINDEX);
    __u32 src_label = ctx_load_meta (ctx, CB_SRC_LABEL);
    bool from_host = ctx_load_meta (ctx, CB_FROM_HOST);
    bool proxy_redirect __maybe_unused = false;
    __u16 proxy_port = 0;
    enum ct_status ct_status = 0;
    ctx_store_meta (ctx, CB_SRC_LABEL, 0);
    ctx_store_meta (ctx, CB_FROM_HOST, 0);
    ret = ipv6_policy (ctx, ifindex, src_label, & ct_status, & tuple, & proxy_port, from_host);
    if (ret == POLICY_ACT_PROXY_REDIRECT) {
        ret = ctx_redirect_to_proxy6 (ctx, & tuple, proxy_port, from_host);
        proxy_redirect = true;
    }
    if (IS_ERR (ret))
        return send_drop_notify (ctx, src_label, SECLABEL, LXC_ID, ret, CTX_ACT_DROP, METRIC_INGRESS);
    ctx_store_meta (ctx, CB_PROXY_MAGIC, ctx->mark);

#ifdef ENABLE_CUSTOM_CALLS
    if (!proxy_redirect && !encode_custom_prog_meta (ctx, ret, src_label)) {
        tail_call_static (ctx, &CUSTOM_CALLS_MAP, CUSTOM_CALLS_IDX_IPV6_INGRESS);
        update_metrics (ctx_full_len (ctx), METRIC_INGRESS, REASON_MISSED_CUSTOM_CALL);
    }

#endif
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_ipv6_to_endpoint (struct  __ctx_buff *ctx)" startline="1584" endline="1659">
int tail_ipv6_to_endpoint (struct  __ctx_buff *ctx)
{
    __u32 src_identity = ctx_load_meta (ctx, CB_SRC_LABEL);
    bool proxy_redirect __maybe_unused = false;
    void *data, *data_end;
    struct ipv6hdr *ip6;
    __u16 proxy_port = 0;
    enum ct_status ct_status;
    int ret;
    if (!revalidate_data (ctx, &data, &data_end, &ip6)) {
        ret = DROP_INVALID;
        goto out;
    }
    if (identity_is_reserved (src_identity)) {
        union v6addr *src = (union v6addr *) &ip6->saddr;
        struct remote_endpoint_info *info;
        info = lookup_ip6_remote_endpoint (src);
        if (info != NULL) {
            __u32 sec_label = info->sec_label;
            if (sec_label) {
                if (sec_label != HOST_ID)
                    src_identity = sec_label;
            }
        }
        cilium_dbg (ctx, info ? DBG_IP_ID_MAP_SUCCEED6 : DBG_IP_ID_MAP_FAILED6, ((__u32 *) src)[3], src_identity);
    }
    cilium_dbg (ctx, DBG_LOCAL_DELIVERY, LXC_ID, SECLABEL);

#ifdef LOCAL_DELIVERY_METRICS
    update_metrics (ctx_full_len (ctx), METRIC_INGRESS, REASON_FORWARDED);

#endif
    ctx_store_meta (ctx, CB_SRC_LABEL, 0);
    ret = ipv6_policy (ctx, 0, src_identity, & ct_status, NULL, & proxy_port, true);
    if (ret == POLICY_ACT_PROXY_REDIRECT) {
        ret = ctx_redirect_to_proxy_hairpin_ipv6 (ctx, proxy_port);
        proxy_redirect = true;
    }
out :
    if (IS_ERR (ret))
        return send_drop_notify (ctx, src_identity, SECLABEL, LXC_ID, ret, CTX_ACT_DROP, METRIC_INGRESS);

#ifdef ENABLE_CUSTOM_CALLS
    if (!proxy_redirect && !encode_custom_prog_meta (ctx, ret, src_identity)) {
        tail_call_static (ctx, &CUSTOM_CALLS_MAP, CUSTOM_CALLS_IDX_IPV6_INGRESS);
        update_metrics (ctx_full_len (ctx), METRIC_INGRESS, REASON_MISSED_CUSTOM_CALL);
    }

#endif
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="static __always_inline int ipv4_policy (struct  __ctx_buff *ctx, int ifindex, __u32 src_label, enum ct_status *ct_status, struct ipv4_ct_tuple *tuple_out, __u16 *proxy_port, bool from_host __maybe_unused)" startline="1671" endline="1879">
static __always_inline int ipv4_policy (struct  __ctx_buff *ctx, int ifindex, __u32 src_label, enum ct_status *ct_status, struct ipv4_ct_tuple *tuple_out, __u16 *proxy_port, bool from_host __maybe_unused)
{
    struct ct_state ct_state_on_stack __maybe_unused, *ct_state, ct_state_new = {};
    struct ipv4_ct_tuple tuple_on_stack __maybe_unused, *tuple;
    void *data, *data_end;
    struct iphdr *ip4;
    bool skip_ingress_proxy = false;
    bool is_untracked_fragment = false;
    struct ct_buffer4 *ct_buffer;
    __u32 monitor = 0, zero = 0;
    enum trace_reason reason;
    int ret, verdict = 0;
    __be32 orig_sip;
    __u8 policy_match_type = POLICY_MATCH_NONE;
    __u8 audited = 0;
    bool emit_policy_verdict = true;
    if (!revalidate_data (ctx, &data, &data_end, &ip4))
        return DROP_INVALID;
    policy_clear_mark (ctx);
    skip_ingress_proxy = tc_index_skip_ingress_proxy (ctx);
    orig_sip = ip4->saddr;

#ifndef ENABLE_IPV4_FRAGMENTS
    is_untracked_fragment = ipv4_is_fragment (ip4);

#endif
    ct_buffer = map_lookup_elem (& CT_TAIL_CALL_BUFFER4, & zero);
    if (!ct_buffer)
        return DROP_INVALID_TC_BUFFER;
    if (ct_buffer->tuple.saddr == 0)
        return DROP_INVALID_TC_BUFFER;

#if HAVE_DIRECT_ACCESS_TO_MAP_VALUES
    tuple = (struct ipv4_ct_tuple *) &ct_buffer->tuple;
    ct_state = (struct ct_state *) &ct_buffer->ct_state;

#else
    memcpy (&tuple_on_stack, &ct_buffer->tuple, sizeof (tuple_on_stack));
    tuple = &tuple_on_stack;
    memcpy (&ct_state_on_stack, &ct_buffer->ct_state, sizeof (ct_state_on_stack));
    ct_state = &ct_state_on_stack;

#endif /* HAVE_DIRECT_ACCESS_TO_MAP_VALUES */
    monitor = ct_buffer->monitor;
    ret = ct_buffer->ret;
    *ct_status = (enum ct_status) ret;
    relax_verifier ();
    if ((ret == CT_REPLY || ret == CT_RELATED) && (ct_state_is_from_l7lb (ct_state) || (ct_state->proxy_redirect && !tc_index_skip_egress_proxy (ctx)))) {
        send_trace_notify4 (ctx, TRACE_TO_PROXY, src_label, SECLABEL, orig_sip, 0, ifindex, (enum trace_reason) ret, monitor);
        if (tuple_out)
            *tuple_out = *tuple;
        return POLICY_ACT_PROXY_REDIRECT;
    }
    if (unlikely (ret == CT_REPLY && ct_state->rev_nat_index && !ct_state->loopback)) {
        struct csum_offset csum_off = {}
        ;
        bool has_l4_header = false;
        int ret2, l4_off;
        l4_off = ETH_HLEN + ipv4_hdrlen (ip4);
        has_l4_header = ipv4_has_l4_header (ip4);
        if (has_l4_header)
            csum_l4_offset_and_flags (tuple->nexthdr, &csum_off);
        ret2 = lb4_rev_nat (ctx, ETH_HLEN, l4_off, & csum_off, ct_state, tuple, REV_NAT_F_TUPLE_SADDR, has_l4_header);
        if (IS_ERR (ret2))
            return ret2;
    }

#if defined(ENABLE_PER_PACKET_LB) && !defined(DISABLE_LOOPBACK_LB)
    if (unlikely (ct_state->loopback))
        goto skip_policy_enforcement;

#endif /* ENABLE_PER_PACKET_LB && !DISABLE_LOOPBACK_LB */
    verdict = policy_can_access_ingress (ctx, src_label, SECLABEL, tuple -> dport, tuple -> nexthdr, is_untracked_fragment, & policy_match_type, & audited);
    if (ret != CT_REPLY && ret != CT_RELATED && verdict < 0) {
        send_policy_verdict_notify (ctx, src_label, tuple->dport, tuple->nexthdr, POLICY_INGRESS, 0, verdict, policy_match_type, audited);
        return verdict;
    }
    if (skip_ingress_proxy) {
        verdict = 0;
        emit_policy_verdict = false;
    }
    if (emit_policy_verdict && (ret == CT_NEW || ret == CT_REOPENED)) {
        send_policy_verdict_notify (ctx, src_label, tuple->dport, tuple->nexthdr, POLICY_INGRESS, 0, verdict, policy_match_type, audited);
    }

#if defined(ENABLE_PER_PACKET_LB) && !defined(DISABLE_LOOPBACK_LB)
skip_policy_enforcement :

#endif /* ENABLE_PER_PACKET_LB && !DISABLE_LOOPBACK_LB */

#ifdef ENABLE_NODEPORT
    if (ret == CT_NEW || ret == CT_REOPENED) {
        bool dsr = false;

# ifdef ENABLE_DSR
        int ret2;
        ret2 = handle_dsr_v4 (ctx, & dsr);
        if (ret2 != 0)
            return ret2;
        ct_state_new.dsr = dsr;
        if (ret == CT_REOPENED && ct_state->dsr != dsr)
            ct_update4_dsr (get_ct_map4 (tuple), tuple, dsr);

# endif /* ENABLE_DSR */
        if (!dsr) {
            bool node_port = ct_has_nodeport_egress_entry4 (get_ct_map4 (tuple), tuple);
            ct_state_new.node_port = node_port;
            if (ret == CT_REOPENED && ct_state->node_port != node_port)
                ct_update_nodeport (get_ct_map4 (tuple), tuple, node_port);
        }
    }

#endif /* ENABLE_NODEPORT */
    if (ret == CT_NEW) {
        ct_state_new.src_sec_id = src_label;
        ret = ct_create4 (get_ct_map4 (tuple), & CT_MAP_ANY4, tuple, ctx, CT_INGRESS, & ct_state_new, verdict > 0, false);
        if (IS_ERR (ret))
            return ret;
    }
    if (!revalidate_data (ctx, &data, &data_end, &ip4))
        return DROP_INVALID;
    reason = (enum trace_reason) *ct_status;
    if (redirect_to_proxy (verdict, *ct_status)) {
        *proxy_port = (__u16) verdict;
        send_trace_notify4 (ctx, TRACE_TO_PROXY, src_label, SECLABEL, orig_sip, bpf_ntohs (*proxy_port), ifindex, reason, monitor);
        if (tuple_out)
            *tuple_out = *tuple;
        return POLICY_ACT_PROXY_REDIRECT;
    }
    send_trace_notify4 (ctx, TRACE_TO_LXC, src_label, SECLABEL, orig_sip, LXC_ID, ifindex, reason, monitor);

#if !defined(ENABLE_ROUTING) && defined(TUNNEL_MODE) && !defined(ENABLE_NODEPORT)
    ctx_change_type (ctx, PACKET_HOST);

#else
    ifindex = ctx_load_meta (ctx, CB_IFINDEX);
    if (ifindex)
        return redirect_ep (ctx, ifindex, from_host);

#endif /* !ENABLE_ROUTING && TUNNEL_MODE && !ENABLE_NODEPORT */
    return CTX_ACT_OK;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_ipv4_policy (struct  __ctx_buff *ctx)" startline="1883" endline="1924">
int tail_ipv4_policy (struct  __ctx_buff *ctx)
{
    struct ipv4_ct_tuple tuple = {}
    ;
    int ret, ifindex = ctx_load_meta (ctx, CB_IFINDEX);
    __u32 src_label = ctx_load_meta (ctx, CB_SRC_LABEL);
    bool from_host = ctx_load_meta (ctx, CB_FROM_HOST);
    bool proxy_redirect __maybe_unused = false;
    enum ct_status ct_status = 0;
    __u16 proxy_port = 0;
    ctx_store_meta (ctx, CB_SRC_LABEL, 0);
    ctx_store_meta (ctx, CB_FROM_HOST, 0);
    ret = ipv4_policy (ctx, ifindex, src_label, & ct_status, & tuple, & proxy_port, from_host);
    if (ret == POLICY_ACT_PROXY_REDIRECT) {
        ret = ctx_redirect_to_proxy4 (ctx, & tuple, proxy_port, from_host);
        proxy_redirect = true;
    }
    if (IS_ERR (ret))
        return send_drop_notify (ctx, src_label, SECLABEL, LXC_ID, ret, CTX_ACT_DROP, METRIC_INGRESS);
    ctx_store_meta (ctx, CB_PROXY_MAGIC, ctx->mark);

#ifdef ENABLE_CUSTOM_CALLS
    if (!proxy_redirect && !encode_custom_prog_meta (ctx, ret, src_label)) {
        tail_call_static (ctx, &CUSTOM_CALLS_MAP, CUSTOM_CALLS_IDX_IPV4_INGRESS);
        update_metrics (ctx_full_len (ctx), METRIC_INGRESS, REASON_MISSED_CUSTOM_CALL);
    }

#endif
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int tail_ipv4_to_endpoint (struct  __ctx_buff *ctx)" startline="1927" endline="2001">
int tail_ipv4_to_endpoint (struct  __ctx_buff *ctx)
{
    __u32 src_identity = ctx_load_meta (ctx, CB_SRC_LABEL);
    bool proxy_redirect __maybe_unused = false;
    void *data, *data_end;
    struct iphdr *ip4;
    __u16 proxy_port = 0;
    enum ct_status ct_status;
    int ret;
    if (!revalidate_data (ctx, &data, &data_end, &ip4)) {
        ret = DROP_INVALID;
        goto out;
    }
    if (identity_is_reserved (src_identity)) {
        struct remote_endpoint_info *info;
        info = lookup_ip4_remote_endpoint (ip4 -> saddr);
        if (info != NULL) {
            __u32 sec_label = info->sec_label;
            if (sec_label) {
                if (sec_label != HOST_ID)
                    src_identity = sec_label;
            }
        }
        cilium_dbg (ctx, info ? DBG_IP_ID_MAP_SUCCEED4 : DBG_IP_ID_MAP_FAILED4, ip4->saddr, src_identity);
    }
    cilium_dbg (ctx, DBG_LOCAL_DELIVERY, LXC_ID, SECLABEL);

#ifdef LOCAL_DELIVERY_METRICS
    update_metrics (ctx_full_len (ctx), METRIC_INGRESS, REASON_FORWARDED);

#endif
    ctx_store_meta (ctx, CB_SRC_LABEL, 0);
    ret = ipv4_policy (ctx, 0, src_identity, & ct_status, NULL, & proxy_port, true);
    if (ret == POLICY_ACT_PROXY_REDIRECT) {
        ret = ctx_redirect_to_proxy_hairpin_ipv4 (ctx, proxy_port);
        proxy_redirect = true;
    }
out :
    if (IS_ERR (ret))
        return send_drop_notify (ctx, src_identity, SECLABEL, LXC_ID, ret, CTX_ACT_DROP, METRIC_INGRESS);

#ifdef ENABLE_CUSTOM_CALLS
    if (!proxy_redirect && !encode_custom_prog_meta (ctx, ret, src_identity)) {
        tail_call_static (ctx, &CUSTOM_CALLS_MAP, CUSTOM_CALLS_IDX_IPV4_INGRESS);
        update_metrics (ctx_full_len (ctx), METRIC_INGRESS, REASON_MISSED_CUSTOM_CALL);
    }

#endif
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int handle_policy (struct  __ctx_buff *ctx)" startline="2024" endline="2061">
int handle_policy (struct  __ctx_buff *ctx)
{
    __u32 src_label = ctx_load_meta (ctx, CB_SRC_LABEL);
    __u16 proto;
    int ret;
    if (!validate_ethertype (ctx, &proto)) {
        ret = DROP_UNSUPPORTED_L2;
        goto out;
    }
    switch (proto) {

#ifdef ENABLE_IPV6
    case bpf_htons (ETH_P_IPV6) :
        invoke_tailcall_if (__and (is_defined (ENABLE_IPV4), is_defined (ENABLE_IPV6)), CILIUM_CALL_IPV6_CT_INGRESS_POLICY_ONLY, tail_ipv6_ct_ingress_policy_only);
        break;

#endif /* ENABLE_IPV6 */

#ifdef ENABLE_IPV4
    case bpf_htons (ETH_P_IP) :
        invoke_tailcall_if (__and (is_defined (ENABLE_IPV4), is_defined (ENABLE_IPV6)), CILIUM_CALL_IPV4_CT_INGRESS_POLICY_ONLY, tail_ipv4_ct_ingress_policy_only);
        break;

#endif /* ENABLE_IPV4 */
    default :
        ret = DROP_UNKNOWN_L3;
        break;
    }
out :
    if (IS_ERR (ret))
        return send_drop_notify (ctx, src_label, SECLABEL, LXC_ID, ret, CTX_ACT_DROP, METRIC_INGRESS);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int handle_policy_egress (struct  __ctx_buff *ctx)" startline="2072" endline="2113">
int handle_policy_egress (struct  __ctx_buff *ctx)
{
    __u16 proto;
    int ret;
    if (!validate_ethertype (ctx, &proto)) {
        ret = DROP_UNSUPPORTED_L2;
        goto out;
    }
    ctx_store_meta (ctx, CB_FROM_HOST, FROM_HOST_L7_LB);
    edt_set_aggregate (ctx, 0);
    send_trace_notify (ctx, TRACE_FROM_PROXY, SECLABEL, 0, 0, 0, TRACE_REASON_UNKNOWN, TRACE_PAYLOAD_LEN);
    switch (proto) {

#ifdef ENABLE_IPV6
    case bpf_htons (ETH_P_IPV6) :
        ep_tail_call (ctx, CILIUM_CALL_IPV6_FROM_LXC);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#endif /* ENABLE_IPV6 */

#ifdef ENABLE_IPV4
    case bpf_htons (ETH_P_IP) :
        ep_tail_call (ctx, CILIUM_CALL_IPV4_FROM_LXC);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#endif /* ENABLE_IPV4 */
    default :
        ret = DROP_UNKNOWN_L3;
        break;
    }
out :
    if (IS_ERR (ret))
        return send_drop_notify (ctx, SECLABEL, 0, LXC_ID, ret, CTX_ACT_DROP, METRIC_EGRESS);
    return ret;
}
</source>
<source file="/home/palani/github/opened_extraction/examples/cilium/bpf_lxc.c" funcheader="int handle_to_container (struct  __ctx_buff *ctx)" startline="2120" endline="2195">
int handle_to_container (struct  __ctx_buff *ctx)
{
    enum trace_point trace = TRACE_FROM_STACK;
    __u32 magic, identity = 0;
    __u16 proto;
    int ret;
    if (!validate_ethertype (ctx, &proto)) {
        ret = DROP_UNSUPPORTED_L2;
        goto out;
    }
    bpf_clear_meta (ctx);
    magic = inherit_identity_from_host (ctx, & identity);
    if (magic == MARK_MAGIC_PROXY_INGRESS || magic == MARK_MAGIC_PROXY_EGRESS)
        trace = TRACE_FROM_PROXY;

#if defined(ENABLE_L7_LB)
    else if (magic == MARK_MAGIC_PROXY_EGRESS_EPID) {
        tail_call_dynamic (ctx, &POLICY_EGRESSCALL_MAP, identity);
        return DROP_MISSED_TAIL_CALL;
    }

#endif
    send_trace_notify (ctx, trace, identity, 0, 0, ctx->ingress_ifindex, TRACE_REASON_UNKNOWN, TRACE_PAYLOAD_LEN);

#if defined(ENABLE_HOST_FIREWALL) && !defined(ENABLE_ROUTING)
    if (identity == HOST_ID) {
        ctx_store_meta (ctx, CB_FROM_HOST, 1);
        ctx_store_meta (ctx, CB_DST_ENDPOINT_ID, LXC_ID);
        tail_call_static (ctx, &POLICY_CALL_MAP, HOST_EP_ID);
        return DROP_MISSED_TAIL_CALL;
    }

#endif /* ENABLE_HOST_FIREWALL && !ENABLE_ROUTING */
    ctx_store_meta (ctx, CB_SRC_LABEL, identity);
    switch (proto) {

#if defined(ENABLE_ARP_PASSTHROUGH) || defined(ENABLE_ARP_RESPONDER)
    case bpf_htons (ETH_P_ARP) :
        ret = CTX_ACT_OK;
        break;

#endif

#ifdef ENABLE_IPV6
    case bpf_htons (ETH_P_IPV6) :
        ep_tail_call (ctx, CILIUM_CALL_IPV6_CT_INGRESS);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#endif /* ENABLE_IPV6 */

#ifdef ENABLE_IPV4
    case bpf_htons (ETH_P_IP) :
        ep_tail_call (ctx, CILIUM_CALL_IPV4_CT_INGRESS);
        ret = DROP_MISSED_TAIL_CALL;
        break;

#endif /* ENABLE_IPV4 */
    default :
        ret = DROP_UNKNOWN_L3;
        break;
    }
out :
    if (IS_ERR (ret))
        return send_drop_notify (ctx, identity, SECLABEL, LXC_ID, ret, CTX_ACT_DROP, METRIC_INGRESS);
    return ret;
}
</source>
</doc>
