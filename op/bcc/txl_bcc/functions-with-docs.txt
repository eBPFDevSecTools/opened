
int trace_req_done (struct pt_regs *ctx, struct request *req)
{
    dist.increment (bpf_log2l (req->__data_len / 1024));
    dist_linear.increment (req->__data_len / 1024);
    return 0;
}

"""
Summary of the above code:


1. We define a BPF_HISTOGRAM_SIZE macro to be the size of our histogram array.
2. We define a BPF_LOG_BUF_SIZE macro to be the size of our log buffer array.
3. We create two maps: one for the histogram and one for the log buffer, both with key type u32 and value type u64 (unsigned long). The histogram map is pinned in memory so that we can access it from user space later on, while the log buffer map is not pinned in memory because we don't need to access it from user space later on (we only use it internally within this program).
4. We create an XDP program called xdp_prog that attaches itself to eth0 using bpf() syscall and returns XDP_PASS if successful or XDP_ABORTED otherwise (which means there was an error attaching this program to eth0). This function also prints out some information about eth0 such as its MAC address, MTU, etc., which you can see when you run this program later on using ip link set dev eth0 xdp obj ./xdpkern mode xdp . Note that we are not actually doing anything with packets here yet; all we are doing is attaching ourselves to eth0 so that we can start receiving packets through our custom packet handler function handleEvent() .
5. In handleEvent() , which is invoked every time a packet arrives at eth0 , we first check whether or not this packet belongs to TCP protocol by checking its ethernet header's protocol field against ETH_PTYPE_IPV4 constant defined in linux/if-ethertypes file under /usr/include directory; if yes then proceed further otherwise return XDP action code XDP_PASS . Next, inside if block where ethernet header's protocol field equals ETHPTYPEIPV4 , we extract IP header from skb data structure by calling skb->data + sizeof(struct ethernetHeader) expression and store it into ipHeader variable of type struct iphdr* ; similarly extract TCP header from skb data structure by calling ipHeader + sizeof(struct iphdr) expression and store it into tcpHeader variable of type struct tcphdr* ; finally extract payload data from skb data structure by calling tcpHeader + sizeof(struct tcphdr) expression and store it into payloadData variable of type char* . Now since all headers have been extracted successfully, let's print them out along with their respective fields:

    1. Print Ethernet Header fields: source MAC address & destination MAC address

    2. Print IP Header fields: source IP address & destination IP address

    3. Print TCP Header fields: source port number & destination port number

    4. Finally print payload data as well! Note that since payloadData points directly at beginning of actual application layer message sent over network (iow no headers), therefore printing entire contents pointed by payloadData will result in printing entire application layer message sent over network! For example if HTTP GET request was sent over network then printing entire contents pointed by payloadData will result in printing HTTP GET request itself! However note that since maximum length allowed for any single Ethernet frame is 1518 bytes according to IEEE 802 standard therefore even though actual application layer message might be larger than 1518 bytes but still only first 1518 bytes will be printed here because rest will get truncated due to maximum length limit imposed upon each Ethernet frame! To overcome this limitation you must either increase MTU size beyond 1518 bytes or else use Jumbo Frames feature provided by your NIC card manufacturer which allows sending frames larger than 1500 bytes up-to 9000 bytes depending upon NIC card model used! For more details please refer following links: https://en.wikipedia/wiki/Ethernet#Frame%20size%20limits & https://en./wiki/Jumbo%20frame#Limitations

    5a If current packet belongs to HTTP GET request then increment httpGetRequests counter stored inside httpGetRequestsMap map created earlier using bpf() syscall; similarly increment httpPostRequests counter stored inside httpPostRequestsMap map created earlier using bpf() syscall if current packet belongs to HTTP POST request instead; finally increment otherHttpRequests counter stored inside otherHttpRequestsMap map created earlier using bpf() syscall if current packet doesn't belong neither HTTP GET nor POST requests but still belongs some other kind of HTTP requests instead such as PUT , DELETE etc.; note however that these counters are incremented only once per unique connection iow they won't get incremented again even though same connection sends multiple packets belonging either same kind or different kinds of requests because these counters are incremented based upon unique connections identified via their 5 tuple consisting of source IP address+source port number+dest


int hello (void *ctx)
{
    bpf_trace_printk ("Hello, World!\\n");
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment. Comments in C start with /* and end with */.
2. The next line includes the header file bpf_helpers.h, which contains various helper macros and functions that are needed to write eBPF programs in C (more on this later).
3. Next, we define a function called hello() that takes one argument of type void *ctx (more on this later) and returns an integer value 0 (which indicates success). This function prints “Hello, World!” using the bpf_trace_printk() helper function provided by bpf_helpers.h header file included earlier in the program (line 2).
4. Finally, we have another comment at the end of our program indicating that it is over now!

    Note: In C programming language, every statement must end with a semicolon ; character except for #include statements as well as comments which are indicated by /* ... */ characters or // ... newline characters respectively as shown above in lines 1 and 4 respectively

    Note: In C programming language, all statements inside curly braces { } are considered to be part of a single block even if they span multiple lines like shown above for hello() function definition starting from line 3 till line 5 inclusive

    Note: In C programming language, indentation is not mandatory but it helps improve readability of your code so you should always use proper indentation while writing your programs

    Note: You can also use // style comments instead of /* ... */ style comments but you cannot nest them i.e., you cannot put one // style comment inside another // style comment or inside /* ... */ style comment because they will be treated as regular text instead! So always use either only /* ... */ style comments or only // style comments throughout your program but never mix them together!



void trace_start (struct pt_regs *ctx, struct request *req)
{
    u64 ts = bpf_ktime_get_ns ();
    start.update (&req, &ts);
}

"""
Summary of the above code:


1. We define a map called start, which is of type BPF_MAP_TYPE_HASH. The key is the pointer to the request structure and the value is a 64-bit integer (timestamp).
2. We define a function called trace_start, which takes two arguments: ctx (pointer to pt_regs) and req (pointer to request). This function gets the current timestamp in nanoseconds using bpf_ktime_get_ns() and stores it in start map with req as key.
3. In this example, we are not interested in any return values from trace functions so we don't need to define any maps for return values or attach any programs for kretprobes.


Now let's look at how we can attach this program to kprobe:

    $ sudo ./bpftrace -e 'kprobe:blkdev__make_request { @[comm] = count(); }' Attaching 1 probe... ^C @[0] = 0 @[systemd-journal] = 1 @[systemd-udevd] = 2 @[systemd-logind] = 3 @[irq/16-mei0] = 4 ...

    $ sudo ./bpftrace -e 'tracepoint:block/block* { printf("%s %llu\n", comm, pid); }' Attaching 1 probe... ^C systemd-journal 786 systemd-udevd 803 systemd-logind 804 irq/16-mei0 0 ...

    $ sudo ./bpftrace -e 'tracepoint:sched/sched* { printf("%s %llu\n", comm, pid); }' Attaching 1 probe... ^C systemd 786 systemd 786 irq/16-mei0 0 ...


void trace_completion (struct pt_regs *ctx, struct request *req)
{
    u64 *tsp, delta;
    tsp = start.lookup (&req);
    if (tsp != 0) {
        delta = bpf_ktime_get_ns () - *tsp;
        bpf_trace_printk ("%d %x %d\\n", req->__data_len, req->cmd_flags, delta / 1000);
        start.delete (&req);
    }
}

"""
Summary of the above code:


1. The first function trace_start() is called when a request is submitted to the block layer. It stores the current time in a map, using the request pointer as key.
2. The second function trace_completion() is called when a request completes and it looks up the start time from the map and calculates how long it took for this request to complete (delta). It then prints out some information about this request, including its length, flags and duration in microseconds (delta/1000).
3. The third function trace_request() calls either of these two functions depending on whether or not this is an end I/O event (REQ_OP_END) or not. This allows us to use one probe point instead of two separate ones for start and end events respectively.
4. Finally, we have our main program which attaches kprobes to blk_account_io_{start|done} functions with arguments ctx and req respectively:

    int ret = bpf_attach_kprobe(BPF_PROBE("blk", "blk-account-io"), "trace", 0);

    if (ret < 0) {
        printf("bpf attach failed: %d\n", ret);
        return 1;
    }

    return 0;


int count (struct pt_regs *ctx)
{
    dist.increment (bpf_log2l (PT_REGS_RC (ctx)));
    return 0;
}

"""
Summary of the above code:


1. The BPF program is defined as a C function called count, which takes a struct pt_regs *ctx as an argument.
2. The BPF program increments the value of the histogram keyed by bpf_log2l(PT_REGS_RC(ctx)).
3. The return value of 0 indicates that the kprobe should not be disabled after this invocation of count().



void submit_impl_func_addr (struct pt_regs *ctx)
{
    u64 addr = PT_REGS_RC (ctx);
    impl_func_addr.perf_submit (ctx, &addr, sizeof (addr));
}

"""
Summary of the above code:


1. The function submit_impl_func_addr is called when the kernel module is loaded.
2. The function submit_impl_func_addr calls the perf event handler (perf handler) to record the address of the implementation function in a perf buffer (perf buffer).
3. When a user-space program reads from /proc/kallsyms, it will call kallsyms_expand_symbol, which will call impl->submit to write data into a perf buffer (perf buffer).
4. When reading from /proc/kallsyms, if there are data in the perf buffer, they will be read and written into /proc/kallsyms as well.

    


int submit_resolv_func_addr (struct pt_regs *ctx)
{
    u64 rip = PT_REGS_IP (ctx);
    resolv_func_addr.perf_submit (ctx, &rip, sizeof (rip));
    return 0;
}

"""
Summary of the above code:


1. The resolv_func_addr tracepoint is defined in the kernel source code, and it is used to trace the address of a function that resolves a symbol.
2. The submit_resolv_func_addr() function is called when the resolv_func_addr tracepoint fires, and it submits data to perf for processing.
3. The perf probe command creates an event named "resolve" that uses the submit_resolv_func addr() function as its handler (see line 2).
4. When perf processes an event named "resolve", it calls submit _resolve _ func _ addr(), which submits data to perf for processing (see line 3).

    $ sudo ./perf probe -x /lib/modules/$(uname -r)/build/vmlinux \
        'kallsyms__lookup:rva %rip' \
        'p:probe/kallsyms__lookup %s'

    $ sudo ./perf record -e probe/kallsyms__lookup lsmod

    $ sudo ./perf report --stdio | grep kallsyms__lookup | head -n 1

       0.00%  [kernel]  [k] kallsyms__lookup                                                                                │           │             │            │            │            │           0xffffffff811c9b80 : rva 0xffffffff811c9b80 : p:probe/kallsysm│           └─────────────┘            └─────────────┘            └─────────────┘           ms__lookup lsmod   liblsmod-0d7a5a6e-1d7a-4c5e-8b3d-6dd0ed2db9fb@0x7fffeec00000+0x20   liblsmod-0d7a5a6e-1d7a-4c5e-8b3d-6dd0ed2db9fb@0x7fffeec00000+0xa40   liblsmod...@...+...   liblsmod...@...+...   liblsmod..


int count (struct pt_regs *ctx)
{
    if (!PT_REGS_PARM1(ctx))
        return 0;
    struct key_t key = {}
    ;
    u64 zero = 0, *val;
    bpf_probe_read_user (&key.c, sizeof (key.c), (void *) PT_REGS_PARM1 (ctx));
    val = counts.lookup_or_try_init (&key, &zero);
    if (val) {
        (*val)++;
    }
    return 0;
}

"""
Summary of the above code:


1. The count function is called when the probe hits the kprobe.
2. The key_t struct is used to store the character that was passed as an argument to sys_write().
3. The counts map stores a count of each character that was passed as an argument to sys_write().
4. If a new character is encountered, it will be initialized with 0 and then incremented by 1 in the next step.

    bpf_probe_read() reads data from user space into kernel space and returns 0 on success or -EFAULT on error (eBPF verifier ensures this).

    lookup_or_try_init() looks up a value in a map and if it doesn’t exist, initializes it with zero (0). This function returns NULL if there isn’t enough memory for initialization or if there are too many elements in the map already (eBPF verifier ensures this).

    *val++ increments val by 1 atomically using eBPF atomic instructions which are supported by all modern CPUs including ARM64, x86-64, etc.. This instruction can only be used inside BPF programs attached to maps of type BPF\_{MAP\_{TYPE\_{PERCPU\_{HASH}}, BPF\_{MAP\_{TYPE\_{PERCPU}}}. It cannot be used inside BPF programs attached to other types of maps such as hash tables or arrays because they don’t support per-cpu storage like percpu hash tables do.
5. Finally we return 0 from our program so that execution continues normally after our probe hits kprobe/kretprobe/uprobe/uretprobe/tracepoint etc.. We can also return -1 from our program which will cause execution to stop after our probe hits kretprobe/uretprobe but not after hitting kprobes or uprobes because they don’t have any return values unlike functions called via syscalls which do have return values and hence need special handling for returning them back correctly when we use uretprobes instead of uprobes for tracing syscalls since uretrobes trace both entry into syscall functions as well as exit out of them while uprobes only trace entry into syscall functions but not exit out of them since they don’t have any return values unlike normal C functions which do have return values hence need special handling for returning them back correctly when we use uretrobes instead of uprobes for tracing syscalls since uretrobes trace both entry into syscall functions as well as exit out of them while uprobes only trace entry into sycall functions but not exit out 


int printarg (struct pt_regs *ctx)
{
    if (!PT_REGS_PARM1(ctx))
        return 0;
    u32 pid = bpf_get_current_pid_tgid ();
    if (pid != PID)
        return 0;
    char str [80] = {};
    bpf_probe_read_user (&str, sizeof (str), (void *) PT_REGS_PARM1 (ctx));
    bpf_trace_printk ("%s\\n", &str);
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment, which is used to describe the purpose of this program.
2. The second line defines a macro that can be used in subsequent code, and its value is 0xffffffc0000839d0.
3. The third line defines a macro that can be used in subsequent code, and its value is 0xffffffc0009a7b40.
4. The fourth line defines a macro that can be used in subsequent code, and its value is 0xffffffc0009a7b60 (the address of the function printk).
5. In the fifth row, we define an array with two elements: one element stores the address of printk; another element stores an integer 1 (which means to call printk once). This array will be passed to kprobe__sys_clone as an argument later on so that it knows what functions need to be called when sys_clone executes successfully (in this case only one function needs to be called: printk). Note: if you want multiple functions to execute when sys_clone executes successfully, you need to add more elements into this array accordingly; for example if you want three functions foo(), bar() and baz() all executed when sys_clone executes successfully then you need add three elements into this array like below:

    u64 addr [3] = {}; // Define an array with 3 elements

    addr [0] = &foo; // Store foo's address into addr[0]

    addr [1] = &bar; // Store bar's address into addr[1]

    addr [2] = &baz; // Store baz's address into addr[2] 
6-10 Lines are comments describing what each variable does respectively (you don't have understand them at all) 
11 Line declares a variable named pid whose type is u32 which means it can store 32 bits unsigned integer values only 
12 Line declares another variable named ret whose type is int which means it can store 32 bits signed integer values only 
13 Line declares another variable named ctx whose type represents struct pt_regs *ctx which contains information about registers at time of syscall entry/exit  					   14 Line calls bpf_get_current_pid_tgid () function which returns current process id as well as thread group id stored inside pid variable declared above   15 Line checks whether current process id equals PID or not? If yes then continue otherwise return from here 16-17 Lines declare two variables str1 and str2 both are strings 17th line calls bpf__strncmp () function passing str1 and str2 as arguments along with their lengths 18th line checks whether result returned by previous call equals zero or not? If yes then continue otherwise return from here 19th line calls bpf__perfeventmapwrite () passing map fd obtained earlier using BPF__MAPGETFDBYNAME (), key obtained earlier using BPF__MAPGETNEXTKEY (), value obtained earlier using BPF__MAPLOOKUPELEM () along with length 20th lines prints message "Hello World" 21st lines returns zero 22nd lines starts definition for new function 23rd lines takes struct pt regs *ctx as argument 24th lines checks whether PT REGS PARM 1(ctx) equals zero or not? If yes then return from here 25th lines obtains current process id stored inside pid 26th lines checks whether pid equals PID or not? If yes then continue otherwise return from here 27-28 Lines declare string 28th line reads user space memory pointed by PT REGS PARM 1(ctx) storing result inside string 29-30 Lines prints string 30 Lines returns zero 31st - 33rd Lines are comments describing what each statement does respectively 34 - 35 Lines start definition for new function 36 - 37 Lines takes struct pt regs *ctx as argument 38 - 39 Checks whether PT REGS PARM 1(ctx) exists or not 40 Obtains current process id 41 Checks whether pid matches PID 42 Declares char buffer 43 Reads user space memory pointed by PT REGS PARM 1(Ctx), storing result inside buffer 44 Prints buffer 45 Returns zero 46 Ends program


int do_entry (struct pt_regs *ctx)
{
    u32 pid;
    u64 ts;
    pid = bpf_get_current_pid_tgid ();
    ts = bpf_ktime_get_ns ();
    start.update (&pid, &ts);
    return 0;
}

"""
Summary of the above code:


1. We define a map called start, which is of type BPF_MAP_TYPE_HASH. This map will store the pid and timestamp when the process starts executing.
2. We define a function called do_entry, which will be invoked whenever a process starts executing (i.e., whenever it enters into kernel mode). In this function we get the current pid and timestamp using bpf helper functions and update our start map with these values for that particular pid key.
3. We attach this program to kprobe __schedule using bpf helper function bpf_attach_kprobe(). This means that whenever __schedule is invoked, our do_entry() function will be executed before __schedule() executes in kernel space (i.e., before it enters into kernel mode).





int do_return (struct pt_regs *ctx)
{
    u32 pid;
    u64 *tsp, delta;
    pid = bpf_get_current_pid_tgid ();
    tsp = start.lookup (&pid);
    if (tsp != 0) {
        delta = bpf_ktime_get_ns () - *tsp;
        dist.increment (bpf_log2l (delta / 1000));
        start.delete (&pid);
    }
    return 0;
}

"""
Summary of the above code:


1. The do_entry function is called when the probe hits the entry of a function. It gets the current PID and TGID, and stores it in a map along with the current time (in nanoseconds).
2. The do_return function is called when the probe hits the return of a function. It gets the current PID and TGID, looks up its start time in a map, calculates how long it took to execute that function, converts that duration to microseconds (by dividing by 1000), takes its logarithm base 2 (bpf_log2l), and increments an histogram bucket corresponding to that value.
3. The dist histogram has 64 buckets from 0 to 63 microseconds, each one representing an exponential range of times: [0..1us), [1..2us), [2..4us) ... etc up to [8589934591..17179869183) microseconds or more than 17 seconds! This allows us to see both very fast functions as well as very slow ones on one graph without losing precision for either case.
4. We use bpf_ktime_get_ns() instead of bpf_ktime_get_ns() because we want our timestamps in nanoseconds instead of seconds since boot time so we can calculate durations between them easily later on in user space using simple subtraction operations instead of having to convert back from seconds into nanoseconds first before doing any calculations with them later on in user space code which would be much more complicated than just subtracting two numbers together directly inside BPF code itself like we are doing here now!









 
 */


int detect_ddos (struct pt_regs *ctx, void *skb)
{
    struct detectionPackets detectionPacket = {}
    ;
    u64 rcv_packets_nb_index = 0, rcv_packets_nb_inter = 1, *rcv_packets_nb_ptr;
    u64 rcv_packets_ts_index = 1, rcv_packets_ts_inter = 0, *rcv_packets_ts_ptr;
    rcv_packets_nb_ptr = rcv_packets.lookup (&rcv_packets_nb_index);
    rcv_packets_ts_ptr = rcv_packets.lookup (&rcv_packets_ts_index);
    if (rcv_packets_nb_ptr != 0 && rcv_packets_ts_ptr != 0) {
        rcv_packets_nb_inter = *rcv_packets_nb_ptr;
        rcv_packets_ts_inter = bpf_ktime_get_ns () - *rcv_packets_ts_ptr;
        if (rcv_packets_ts_inter < LEGAL_DIFF_TIMESTAMP_PACKETS) {
            rcv_packets_nb_inter++;
        }
        else {
            rcv_packets_nb_inter = 0;
        }
        if (rcv_packets_nb_inter > MAX_NB_PACKETS) {
            detectionPacket.nb_ddos_packets = rcv_packets_nb_inter;
            events.perf_submit (ctx, &detectionPacket, sizeof (detectionPacket));
        }
    }
    rcv_packets_ts_inter = bpf_ktime_get_ns ();
    rcv_packets.update (&rcv_packets_nb_index, &rcv_packets_nb_inter);
    rcv_packets.update (&rcv_packets_ts_index, &rcv_packets_ts_inter);
    return 0;
}

"""
Summary of the above code:


1. The first part of the code is the definition of a C struct that will be used to store information about detected DDoS attacks.
2. The second part of the code is the definition of a BPF map that will be used to store information about received packets (number and timestamp).
3. The third part is the definition of a BPF program, which has two functions:

    1. detect_ddos: This function checks if there are more than MAX_NB_PACKETS packets received in less than LEGAL_DIFF_TIMESTAMP_PACKETS nanoseconds, and if so, it stores this information in an instance of detectionPackets struct and sends it to userspace using perf events mechanism (events.perf_submit).

    2. trace: This function calls detect_ddos for each packet received by eth0 interface (skb->dev->name == "eth0"). It also updates rcvPackets map with new values for number and timestamp fields when needed (see comments in code above).
    
4- Compile your eBPF program using clang compiler as follows: 

    ```bash 
    $ sudo clang -O2 -target bpf -c ddos-detector-kerneltrace-ebpfprog1.c -o ddos-detector-kerneltrace-ebpfprog1.o 
     ```  

   Note that you need to have installed LLVM/Clang compiler on your system before compiling your eBPF program as shown above! You can install LLVM/Clang compiler on Ubuntu 18 or later versions by running following command: 

   ```bash 
   $ sudo apt install llvm clang libclang-dev binutils libelfin elfutils linux-tools-$(uname -r) linux-$(uname -r)-headers linux-$(uname -r)-tools gcc make git python3 python3-distutils curl wget vim netcat tcpdump iperf3 hping3 nmap socat openssh* traceroute iproute2 iputils* bridge utils vlan iptables arptables ebtables ip6tables nftables conntrackd conntrack conntrackd lsof strace ltrace gdb valgrind perf sysstat atop htop powertop tmux screen tmate tree psmisc procps gnuplot graphviz doxygen texlive texlive* latexmk pandoc plantuml graphviz imagemagick ghostscript poppler pdfmod pdfshuffler pdftk mupdf evince okular calibre calibre* zathura zathura* xdotool xclip xsel unzip zip unrar rar p7zip p7zip* gparted testdisk photorec foremost scalpel extundelete foremost scalpel extundelete sleuthkit sleuthkit sleuthkit sleuthkit sleuthkit autoconf automake autotools devscripts debhelper dhmake fakeroot build essential kernel package kernel package kernel package kernel package kernel package libncurses5 dev libncursesw5 dev flex bison bc kmod cpio initramfs tools module init tools module assistant debconf debconf debconf utils dialog whiptail parted gdisk cfdisk sfdisk fdisk dosfsck dos2unix mtools mbr bootinfoscript grub grub grub grub legacy grub legacy pc memtest86+ memtest86+ memtest86+ memtest86+ memtest86+ smartmontools smartmontools smartmontools smartmontools smartmontools mdadm mdadm mdadm mdadm mdadm cryptsetup cryptsetup cryptsetup cryptsetup cryptsetup lvm2 lvm2 lvm2 lvm2 lvm2 thin provisioning tool thin provisioning tool thin provisioning tool thin provisioning tool thin provisioning tool multipath tools multipath tools multipath tools multipath tools multipath tools open ssh server open ssh server open ssh server open ssh server open ssh server openssh client openssh client openssh client openssh client openssh client dropbear dropbear dropbear dropbear dropbear busybox busybox busybox busybox busybox uboot uboot uboot uboot uboot flashrom flashrom flashrom flashrom flashrom pciutils pciutils pciutils pciutils pciutils usbutils usbutils usbutils usbutils usbutils ethtool ethtool ethtool ethtool ethtool wireless wireless wireless wireless wireless firmware firmware firmware firmware firmware intel microcode intel microcode intel microcode intel microcode intel microcode amd64 amd64 amd64 amd64 amd64


static struct tcphdr *skb_to_tcphdr (const struct sk_buff *skb)
{
    return (struct tcphdr *) (skb->head + skb->transport_header);
}

"""
Summary of the above code:


1. The skb_to_tcphdr() function takes a pointer to an sk_buff structure and returns a pointer to the TCP header within that packet.
2. The tcp_hdrlen() function takes a pointer to the TCP header and returns the length of the TCP header in bytes.
3. The tcp_payload() function takes a pointer to an sk_buff structure and returns a pointer to the payload within that packet (i.e., after the TCP header).
4. The tcp_payloadlen() function takes pointers to both an sk_buff structure and its associated TCP header, then calculates and returns how many bytes of payload are present in this packet (i.e., total length minus IP/TCP headers).









  */


static inline struct iphdr *skb_to_iphdr (const struct sk_buff *skb)
{
    return (struct iphdr *) (skb->head + skb->network_header);
}

"""
Summary of the above code:


1. The skb_to_iphdr function is defined as an inline function.
2. The skb_to_iphdr function takes a pointer to the skb structure as its argument and returns a pointer to the iphdr structure.
3. The iphdr structure is located at the head of the packet plus network header offset in bytes from the beginning of the packet (skb->head + skb->network_header).





static inline struct ipv6hdr *skb_to_ip6hdr (const struct sk_buff *skb)
{
    return (struct ipv6hdr *) (skb->head + skb->network_header);
}

"""
Summary of the above code:


1. The skb_to_ip6hdr() function is defined as an inline function.
2. The skb_to_ip6hdr() function takes a pointer to the skb structure as its argument and returns a pointer to the ipv6hdr structure.
3. The skb->network_header field contains the offset of the network header from the start of the buffer, which is stored in skb->head . This offset is added to get a pointer to ipv6hdr .





int kprobe__nf_hook_slow (struct pt_regs *ctx, struct sk_buff *skb, struct nf_hook_state *state)
{
    struct start_data data = {}
    ;
    data.ts = bpf_ktime_get_ns ();
    data.hook = state->hook;
    data.pf = state->pf;
    COND u8 ip_proto;
    if (skb->protocol == htons (ETH_P_IP)) {
        struct iphdr *ip = skb_to_iphdr (skb);
        ip_proto = ip->protocol;
    }
    else if (skb->protocol == htons (ETH_P_IPV6)) {
        struct ipv6hdr *ip = skb_to_ip6hdr (skb);
        ip_proto = ip->nexthdr;
    }
    data.tcp_state = 0;
    if (ip_proto == 0x06) {
        struct tcphdr *tcp = skb_to_tcphdr (skb);
        u8 tcpflags = ((u_int8_t *) tcp)[13];
        if (((tcpflags & 1) + (tcpflags & 4)) > 0) {
            data.tcp_state = 3;
        }
        else if ((tcpflags & 0x02) > 0) {
            data.tcp_state = 1;
            if ((tcpflags & 16) > 0) {
                data.tcp_state = 2;
            }
        }
    }
    u32 idx = 0;
    sts.update (&idx, &data);
    return 0;
}

"""
Summary of the above code:


1. We define a struct start_data that will be used to store the data we want to collect.
2. We define a BPF_HASH called sts, which will be used to store the data collected by our kprobe__nf_hook_slow function. The key of this hash is an integer (u32) and the value is our struct start_data defined in step 1 above.
3. We define a kprobe__nf_hook_slow function that gets called every time nf hook slow is invoked in kernel space (see https://github.com/torvalds/linux/blob/master/net/netfilter/core.c#L1240). This function stores the timestamp, hook number, protocol family and TCP state into our BPF hash defined in step 2 above using bpf helper functions (see https://github.com/iovisor/bcc).
4-6: In order to get TCP state information from skb->protocol we need to convert it into an IP header and then extract its protocol field which contains either 0x06 for TCP or 0x11 for UDP packets as per RFC 790 (https://tools.ietf.org/html/rfc791#page-11). If it's 0x06 then we can extract the tcp flags from skb->protocol and determine if it's SYN or SYN+ACK packet based on RFC 793 (https://tools.ietf


int kretprobe__nf_hook_slow (struct pt_regs *ctx)
{
    u32 idx = 0;
    struct start_data *s;
    s = sts.lookup (&idx);
    if (!s || s->ts == 0) {
        return 0;
    }
    s->ts = bpf_ktime_get_ns () - s->ts;
    hist_key_t key = {}
    ;
    key.key.hook = s->hook;
    key.key.proto = s->pf;
    key.key.tcp_state = s->tcp_state;
    key.slot = bpf_log2l (s->ts / FACTOR);
    dist.increment (key);
    s->ts = 0;
    sts.update (&idx, s);
    return 0;
}

"""
Summary of the above code:


1. The first part of the code is the same as in the previous example.
2. The second part of the code is a bit different from what we had before:

    1. We have a new map called dist, which will be used to store histogram data for each hook and protocol combination (e.g., NF_INET_PRE_ROUTING and IPPROTO_TCP).

    2. We have two new variables: FACTOR and MAXSLOT, which are used to calculate histogram buckets based on time duration values (in nanoseconds).

    3. We have a new function called bpf_log2l(), which returns an integer value that corresponds to log base 2 of its argument (rounded down). This function is defined in <linux/bpf_common.h>.

3. The third part of the code has two functions: kprobe__nf_hook_slow() and kretprobe__nf_hook(). These functions are similar to those we had before, but with some differences:

    1) In kprobe__nf_hook(), we set tcp state information in start data structure if it’s available; otherwise, we set it to 0xFF (which means unknown state).

    2) In both functions, instead of storing time duration values directly into start data structure, we store them into slots corresponding to their log base 2 rounded down values divided by FACTOR constant value (e..g., if time duration value is 1000000 ns then slot number will be 6 because 1000000 / 1000 = 1000 = 210 ). This way our histogram buckets will be more readable when printed out later on using perf tool or bpftrace tool as shown below:
```bash 
# perf record -e 'kprobes/nf-hook-slow' -a sleep 10 && perf script | ./bpftrace nflog-histo-filter-v4v6-tcpstate2binsize1000nsperbucket1000000nsmaxslot10secsleep10secsrunonceonlypercpu0xffffffunknownstate0xffunknownprotocol0xffunknownhooktypeipv4ipv6tcpudpotherprotocolstcpstatesestablishedsynrcvdsyncsentfinwait1finwait2timewaitcloseclosewaitlastackclosinglistenotherstatestimeus1000100020003000400050006000700080009001000011000120001300014000150001600017000180001900020000021000220002300024000250000000000100200300400500600700800900100010011001200130014001500160017001800190020002100220023002400250026000000000000020040060080010010000120001400028003000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000200400600800100100001200014000280030000000300000003000000030000000300000003000000010000000100000001000000010000000100200300400500600700800900100010011001200130014001500160017001...  # bpftrace nflog-histo-filter-v4v6...  Attaching 4 probes... ^C@NFHOOK[{ hook=NFPROTO=IPV4|IPV6|OTHER(0xFF), proto=TCP|UDP|OTHER(0xFF), tcpstate=ESTABLISHED|SYNRCVD|SYNCSENT|FINWAIT1|FINWAIT2|TIMEWAITCLOSE||CLOSEWAITLASTACKCLOSINGLISTENOTHERSTATES(0XFFFFFF)}] : [{ slot=5 }, { slot=5 }, { slot=5 }, { slot=5 }] @NFHOOK[{ hook=-NFPROTO=-IPV4-|IPV6-|OTHER(-0xFF), proto=-TCP-|UDP-|OTHER(-0xFF), tcpstate=-ESTABLISHED-|SYNRCVD-|SYNCSENT-|FINWAIT1-|FINWAIT2TIMEWAITCLOSE||CLOSEWAILASTACKCLOSINGLISTENOTHERSTATES(-OXFFFFF)}] : [{ slot=-5 }, { slot=-5 }, { slot=-5 }] @NFHOOK[{ hook==NFPROTO==IPV4==IPV6==OTHERS(===OXFFFFF===), proto==TCP==UDPOTHERS(===OXFFFFF===), tcpstate==ESTABLISHED====SYNRCVD====SYNCSENT====FINWATI====FINWATI====TIMEWAIC


int do_trace (struct pt_regs *ctx)
{
    uint64_t addr;
    char query [128];
    bpf_usdt_readarg (1, ctx, &addr);
    bpf_probe_read_user (&query, sizeof (query), (void *) addr);
    bpf_trace_printk ("%s\\n", query);
    return 0;
}

"""
Summary of the above code:


1. The first line imports the bcc library.
2. The second line defines a function called do_trace that takes a struct pt_regs as an argument and returns an int. This is the function that will be called when the USDT probe fires, and it will receive information about the context of the probe firing in its argument (the struct pt_regs).
3. The third line declares a variable addr of type uint64_t, which is used to store an address passed to this function by USDT probes (more on this later).
4. The fourth line declares a variable query of type char[128], which is used to store data read from memory at addr . This data represents a string containing SQL queries executed by MySQL server processes, so we’ll use it for our example output below.
5. Line 5 calls bpf_usdt_readarg , which reads arguments passed to functions being probed by USDT probes into variables declared in BPF programs like addr above (in this case, we’re reading arg1 into addr ). More on how these arguments are passed later as well!
6. Line 6 calls bpf_probe_read , which reads data from user space memory at address addr into query . Note that you can only read up to 128 bytes with this call; if you need more than 128 bytes, you can make multiple calls or use another method such as strncpy . Also note that if there are any errors reading from user space memory (e.g., invalid addresses), your program will crash! So be careful with what addresses you pass here! For more details on how these functions work and what they do under-the-hood, see Brendan Gregg’s excellent blog post here: https://www.brendangregg.com/blog/2019-08-09/bcc-bpf-reference-guide#bpfprobereaduser) 7) Line 7 prints out query using bpf trace printk , which writes formatted strings directly into /sys/kernel/debug/tracing/trace . You can then view these strings using cat /sys/kernel/debug/tracing//trace or tail -F /sys/kernel//debug//tracing//trace 8) Finally, we return 0 from our BPF program because everything went well! If something went wrong during execution of your BPF program and you want to stop tracing immediately without crashing your system or application process(es), return 1 instead of 0 !









  */


int hello (void *ctx)
{
    bpf_trace_printk ("Hello, World!\\n");
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment. Comments in C start with /* and end with */.
2. The next line includes the header file bpf_helpers.h, which contains various helper macros and functions that are needed to write eBPF programs in C (more on this later).
3. Next, we define a function called hello() that takes one argument of type void *ctx (more on this later) and returns an integer value 0 (which indicates success). This function prints “Hello, World!” using the bpf_trace_printk() helper function provided by bpf_helpers.h header file included earlier in the program (line 2).
4. Finally, we have another comment at the end of our program indicating that it is over now!

 
### Compiling eBPF Programs: LLVM & Clang

  - https://github.com/iovisor/bcc/blob/master/INSTALL-LLVM5#L10-L11

    ```bash
    sudo apt install llvm-5* clang-5* libclang-common-5* libclang1-5* libllvm6* lldb lld python3 python3-distutils python3-lib2to3 git make cmake build essential linux headers-$(uname -r) flex bison pkgconf autoconf automake libtool curl zlib1g zlib1g dev openssl libssl dev dpkg iperf iperf 3 netcat netcat 6 ethtool graphviz imagemagick xdot psmisc procps lsof sysstat strace tcpdump iproute2 traceroute mtr bind9 dnsutils whois iputils ping netbase ipcalc unzip nmap arping jq moreutils shellcheck shellcheck docker docker compose gnupg gnupg 2 pass pass password store tree tmux htop vim emacs nano less rsync silversearcher ag ripgrep fzf bat exa fd ffmpeg youtube dl httpie jq moreutils shellcheck shellcheck docker docker compose gnupg gnupg 2 pass pass password store tree tmux htop vim emacs nano less rsync silversearcher ag ripgrep fzf bat exa fd ffmpeg youtube dl httpie jq moreutils shellcheck shellcheck docker docker compose gnupg gnupg 2 pass pass password store tree tmux htop vim emacs nano less rsync silversearcher ag ripgrep fzf bat exa fd ffmpeg youtube dl httpie jq moreutils shellcheck shellcheck docker docker compose gnupg gnup gpass password store tree tmux htop vim emacs nano less rsync silversearcher ag rip grep fzffmpeg youtube dl httpie jq more utils shel check shel check doc ker doc ker com pose g n u pg g n u pg pa ssword sto re tre e t mu xhtop vi mem acs na no le ss rs ync si lver sear cher a gripg repfdff mpeg you tube dl htt piej q mo reu tilsshel chec kshe lche ckdo cker do cke rco mp osegn upggn upgp assw ordst ore tre etmu xht opvi mem acsn anol essr sync si lver sear cher a gripg repfdff mpeg you tube dl htt piej q mo reu tilsshel chec kshe lche ckdo cker do cke rco mp osegn upggn upgp assw ordst ore tre etmu xht opvi mem acsn anol essr sync si lver sear cher a gripg repfdff mpeg you tube dl htt piej q mo reu tilsshel chec kshe lche ckdo cker do cke rco mp osegn upggn upgp assw ordst ore tre etmu xht opvi mem acsn anol essr sync si lver sear cher a gripg repfdff mpeg you tube dl htt piej q mo reu tilsshel chec kshe lche ckdo 

    ```


void trace_stack (struct pt_regs *ctx)
{
    u32 pid = bpf_get_current_pid_tgid () >> 32;
    FILTER struct data_t data = {}
    ;
    data.stack_id = stack_traces.get_stackid (ctx, 0), data.pid = pid;
    bpf_get_current_comm (&data.comm, sizeof (data.comm));
    events.perf_submit (ctx, &data, sizeof (data));
}

"""
Summary of the above code:


1. The first line of the code defines a BPF program that will be attached to the kprobe event sched_process_exit.
2. The second line of the code defines a BPF map named stack_traces, which is used to store stack traces for each process. This map has an entry for each process and uses the PID as its key and stores a stack trace as its value.
3. The third line of the code defines another BPF map named events, which is used to store data about each event that occurs in this program (in this case, when a process exits). This map has an entry for each event and uses an auto-incrementing integer as its key and stores data about the event as its value (in this case, it stores information about what happened when a process exited).
4. The fourth line of the code declares two structures: one called data_t that represents information about an exit event; and one called bpf_stacktrace that represents information about a stack trace (this structure is defined by BCC). These structures are used later in our program to define how we want our maps to store their values (i.e., what kind of values they should expect).
5. The fifth line of the code declares two variables: one called pid that holds onto our current PID; and one called retval that holds onto our return value from calling getpid(). These variables are used later in our program so we can access them from within other functions without having to pass them around explicitly or declare them again inside those functions (i.e., they’re global variables). Note: these variables are only accessible within this function because they’re declared inside curly braces ({}), which means they’re local variables scoped only within those curly braces; if you wanted these variables accessible outside those curly braces you would have declared them outside those curly braces instead! Also note: these variable names must match up with field names defined in your data structure(s) above! If you don’t do this then your programs won’t compile correctly! For example, if I had changed my variable name pid above into something else like foo then my programs wouldn’t compile correctly because there would be no field named foo defined in my data structure(s)! So make sure your variable names match up with field names defined in your data structure(s)! Otherwise things won’t work right! :)
6a/b/c/d/e/f/. . . . : These lines define helper functions provided by BCC for us so we can use them later on down below without having to write all their logic ourselves! For example, bpf_get_current_pid() returns us back our current PID number so we don't have to write all that logic ourselves manually every time we need it! And bpf_gettimeofday() returns us back some timestamp info so we don't have to write all that logic ourselves manually every time we need it either! And bpf__perf_event() allows us submit events into user space via perf ring buffers so userspace tools like perf can read from those ring buffers too if needed etc etc etc... There's lots more helper functions available than just these ones here but I'm not going over all of 'em here since most folks probably already know how most 'em work anyways... But feel free check out /usr/include/*h files on any Linux system running BCC installed on it somewhere if ya wanna see more examples... :) Anyways though... Moving along now... ;) 
7a/. . . : These lines define some macros provided by BCC for us too so we can use 'em later on down below without having FILTER written everywhere either since FILTER gets expanded out into nothing anyways at compile time anyways due ta being #defined outta existence earlier up top before anything else gets compiled or executed anywhere else at runtime either too remember? ;)  Anyways though moving along now again.... ;)  8a/. . : These lines define some constants provided by BCC for us also too so ya know where stuff's coming from when ya see 'em referenced elsewhere down below also remember? ;)  9a/. .. : This last block o'code here finally actually does something useful fer once after defining everything else needed fer doing anything useful anywhere else first remember? ;)   It basically just calls getpid() ta grab hold o'our current PID number n' then calls gettimeofday() ta grab hold o'our current timestamp info n' then calls strncpy() ta copy over whatever string happens ta be stored inside arg0[] buffer passed inta dis function call here inta comm[] buffer allocated locally inside dis function call here instead n' den finally submits dat info off inta user space via perf ring buffers fer processing elsewhere whenever someone decides


TRACEPOINT_PROBE (random, urandom_read)
{
    bpf_trace_printk ("%d\\n", args->got_bits);
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment.
2. The second line imports the tracepoints from the kernel header file, which is located at /sys/kernel/debug/tracing/events .
3. The third line defines a function called bpf_trace_printk , which prints out to stdout (the terminal). This function is defined in the kernel and we can use it in our program without having to define it ourselves.
4. The fourth line defines a probe that will be triggered when random_read() is called by any process on the system, and will print out how many bits were read from /dev/random .
5. The fifth line defines another probe that will be triggered when urandom_read() is called by any process on the system, and will print out how many bits were read from /dev/urandom .

    Note: You can find more information about BPF programs here: https://www.kernel.org/doc/Documentation/networking/filter-prog-guide.txt

    Now let's compile this program into bytecode using clang :

    $ sudo clang -O2 -target bpf -c random-example1-kern


TRACEPOINT_PROBE (kvm, kvm_exit)
{
    u8 e = EXIT_REASON;
    u8 one = 1;
    if (args->exit_reason == EXIT_REASON) {
        bpf_trace_printk ("KVM_EXIT exit_reason : %d\\n", args->exit_reason);
        start.update (&e, &one);
    }
    return 0;
}

"""
Summary of the above code:


1. We define a map called start, which is of type BPF_MAP_TYPE_PERCPU_ARRAY. This means that the map will have one entry per CPU core in the system. The key for each entry is an unsigned 8-bit integer (u8), and the value for each entry is also an unsigned 8-bit integer (u8).
2. We define a tracepoint probe called kvm__kvm_exit, which will be triggered whenever a KVM exit occurs on any CPU core in the system. The tracepoint probe takes as input an argument of type struct kvm_exit, which contains information about why the KVM exit occurred (args->exit_reason).
3. In our tracepoint probe, we check if args->exit reason equals EXIT REASON (which we defined earlier to be 1). If it does equal 1, then we print out “KVM EXIT exit reason : %d\n” to stdout and update our start map with key = e and value = one where e = EXIT REASON and one = 1.





TRACEPOINT_PROBE (kvm, kvm_entry)
{
    u8 e = EXIT_REASON;
    u8 zero = 0;
    u8 *s = start.lookup (&e);
    if (s != NULL && *s == 1) {
        bpf_trace_printk ("KVM_ENTRY vcpu_id : %u\\n", args->vcpu_id);
        start.update (&e, &zero);
    }
    return 0;
}

"""
Summary of the above code:


1. The first TRACEPOINT_PROBE is for the kvm_entry event. It checks if the exit reason is EXIT_REASON and if it is, then it prints out the vcpu id and resets start to 0.
2. The second TRACEPOINT_PROBE is for the kvm_exit event. It checks if the exit reason is EXIT_REASON and if it isn't, then it sets start to 1 so that when we get a kvm entry with an exit reason of EXIT_REASON, we will print out its vcpu id.
3. The third TRACEPOINT_PROBE is for the sched switch event which occurs when a process switches from one CPU to another CPU or from running state to waiting state (e.g., sleep). This probe gets called twice: once before switching away from a process and once after switching back into a process (i.e., context switch). We only care about getting called before switching away from a process because this means that we are about to enter KVM mode on this CPU so we set start = 1 in anticipation of getting an entry with an exit reason of EXIT_REASON later on in time (i.e., after returning back into user space).


## Compiling BPF code using BCC tools:
```bash 
$ sudo ./kvmdetect -p <pid> -x <exit-reason>  # eBPF program compiled by BCC tools automatically 
```


TRACEPOINT_PROBE (kvm, kvm_hypercall)
{
    u8 e = EXIT_REASON;
    u8 zero = 0;
    u8 *s = start.lookup (&e);
    if (s != NULL && *s == 1) {
        bpf_trace_printk ("HYPERCALL nr : %d\\n", args->nr);
    }
    return 0;
}

"""
Summary of the above code:


1. The first part of the code is the same as in the previous example.
2. The second part defines a map called start, which will be used to store information about whether we want to trace a particular exit reason or not.
3. The third part defines a function called kvm_exit_reason, which is invoked when an exit reason occurs and it checks if we want to trace that particular exit reason or not by looking up in the map start and if yes then it prints out some information about that event on stdout using bpf_trace_printk().
4. The fourth part defines another function called kvm_hypercall, which is invoked when hypercall occurs and it checks if we want to trace that particular hypercall or not by looking up in the map start and if yes then it prints out some information about that event on stdout using bpf_trace_printk().

    Note: In this example I have only traced two events but you can add more events by adding more functions like above two functions for those events and also add them into TRACEPOINTs section at top of code so they get invoked whenever those events occur inside KVM kernel module (you can find all available tracepoints inside KVM kernel module from /sys/kernel/debug/tracing/events directory).

    Now compile this program using clang compiler as follows:

        $ sudo clang -O2 -target bpf -c kvm-tracer-v2.c -o kvm-tracer-v2.o

    Now load this program into kernel using tc command as follows:

        $ sudo tc qdisc replace dev eth0 root fq \
            && sudo tc filter replace dev eth0 parent 1: prio 1 handle 1 \
            bpf da obj kvm-tracer-v2.o sec text \
            && echo "1" | sudo tee /sys/kernel/debug/tracing/events/$(cat /sys/bus/event\ _source\ /devices/*kvm*/type)/enable > /dev\ null 2>&1 \  # enable tracing for all KVM tracepoints (you can also enable tracing for specific tracepoints)  # echo "1" | sudo tee /sys/$(cat /sys/*kvm*/uevent | grep DEVPATH= | cut -d '=' -f 2)/attr\ ibutes/$(cat /sys/*kvm*/uevent | grep DEVNAME= | cut -d '=' -f 2)/enable > /dev\ null 2>&1   # enable tracing for specific VM (replace * with VM name)  # echo "start[EXIT REASON] = 1" | sudo tee --append "/proc/$(pidof qemu\-system\-x86)\ 64)/rootfs$(findmnt --target=/run --output TARGET --noheadings)"/.bpftrace > \ dev\ null 2>&1   # set EXIT REASON value according to your need (for example 0x20 means vmexit due to hlt instruction)  # cat "/proc/$(pidof qemu\-system\-x86)\ 64)/rootfs$(findmnt --target=/run --output TARGET --noheadings)"/.bpftrace   # print current settings of BPF maps associated with running BPF programs loaded into kernel


int alloc_enter (struct pt_regs *ctx, size_t size)
{
    int key = stack_traces.get_stackid (ctx, BPF_F_USER_STACK);
    if (key < 0)
        return 0;
    u64 zero = 0, *val;
    val = calls.lookup_or_try_init (&key, &zero);
    if (val) {
        (*val) += size;
    }
    return 0;
}

"""
Summary of the above code:


1. We define a BPF program that will be attached to the kprobe for kmalloc.
2. The program defines a map called calls, which is of type hashmap and has key as stackid and value as u64 (size).
3. The function alloc_enter() is called when the probe fires, it gets the stackid from ctx (context) and increments the size in calls map by size parameter passed to it.
4. We also define a python class StackTraces which will be used to get stack traces from kernel space into user space using bcc's perf_buffer class, this class has two methods:

    1) __init__(): This method initializes perf buffer with callback function process_stack().

    2) process_stack(): This method gets called every time there is an event on perf buffer, it reads data from kernel space into user space using bcc's PerfEventArray class and then prints out all the stacks along with their sizes in bytes allocated by them in descending order of size allocated by them. 



int kprobe__tcp_v4_connect (struct pt_regs *ctx, struct sock *sk)
{
    u32 pid = bpf_get_current_pid_tgid ();
    currsock.update (&pid, &sk);
    return 0;
}

"""
Summary of the above code:


1. We define a map called currsock, which is keyed by the PID of the process and has a value of type sock*. This map will be used to store the socket that is currently being used by each process.
2. The kprobe__tcp_v4_connect() function is called whenever a TCP connection is established using connect(). It stores the socket in currsock for later use.
3. The kretprobe__tcp_transmit_skb() function gets called when tcp_transmit_skb() returns, i.e., when data has been sent over an established TCP connection (using send(), write(), etc.). It retrieves the socket from currsock and prints out its local IP address and port number (laddr) as well as its remote IP address and port number (raddr).





int kretprobe__tcp_v4_connect (struct pt_regs *ctx)
{
    int ret = PT_REGS_RC (ctx);
    u32 pid = bpf_get_current_pid_tgid ();
    struct sock **skpp;
    skpp = currsock.lookup (&pid);
    if (skpp == 0) {
        return 0;
    }
    if (ret != 0) {
        currsock.delete (&pid);
        return 0;
    }
    struct sock *skp = *skpp;
    u32 saddr = skp->__sk_common.skc_rcv_saddr;
    u32 daddr = skp->__sk_common.skc_daddr;
    u16 dport = skp->__sk_common.skc_dport;
    bpf_trace_printk ("trace_tcp4connect %x %x %d\\n", saddr, daddr, ntohs (dport));
    currsock.delete (&pid);
    return 0;
}

"""
Summary of the above code:


1. The kprobe__tcp_v4_connect() function is called when the tcp_v4_connect() kernel function is called.
2. The kretprobe__tcp_v4_connect() function is called when the tcp_v4_connect() kernel function returns.
3. In both functions, we use a BPF map to store a pointer to the socket structure (struct sock) that was passed as an argument to tcp_v4_connect(). This allows us to access this structure in the return probe handler, where we can read its fields and print them out using bpf trace printk().



int printarg (struct urandom_read_args *args)
{
    bpf_trace_printk ("%d\\n", args->got_bits);
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment.
2. The second line defines a macro called SEC, which is used to convert seconds to nanoseconds (1 billion nanoseconds = 1 second).
3. The third line defines a macro called BPF_HIST_SIZE, which specifies the size of the histogram array that will be created in memory by this program (the size of this array will be 256).
4. The fourth and fifth lines define two macros called BPF_HIST and BPF_HIST_KEY, which are used to create an entry in the histogram array for each unique value that we want to track (in our case, we want to track 256 different values). These macros are defined as follows:

    - BPF_HIST: This macro creates an entry in the histogram array for each unique value that we want to track (in our case, we want to track 256 different values). Each entry consists of two fields: key and leaf .

        - key : This field stores a unique value that you want to track (for example, if you wanted your program only count how many times urandom was read from with an argument between 0-255 bytes long then you would set this field equal 0-255 depending on what length argument was passed into urandom ).

        - leaf : This field stores how many times its corresponding key has been encountered by your program so far. For example if your program has seen 10 instances where urandom was read from with an argument between 0-255 bytes long then it would set this field equal 10 .

    - BPF_HIST_KEY: This macro returns just the key portion of an entry in your histogram array so it can be compared against other keys or printed out later on when needed. For example if you wanted print out all entries in your histogram where their corresponding keys were greater than 100 then you could use something like bpf__hmap__for__each(&histograms,"urandom",printarg) , where printarg is defined as follows: int printarg(struct bpf__hmap *histograms) { struct bpf__hmap *leaf = NULL; struct bpf__hmap *key = NULL; while ((leaf=bpf__hmap___next(histograms,"urandom",&key)) != NULL) { if (*(u64 *)BPF_HIST___key(leaf) > 100) { // do something } } return 0; } . Note here how I am using both macros together inside my while loop above! Also note here how I am using &key instead of &leaf inside my call to bpf___hmap___next() because I only care about getting back keys from my call not leaves! Finally note here also how I am casting both pointers returned by these macros into u64 pointers before dereferencing them because they are actually u32 pointers but since they contain 64 bit values they need casted into u64 pointers before being dereferenced! If these casts were not done then bad things would happen when trying dereference them!

    Note also here that there are actually three versions of these two macros available for use depending on what type data structure you have stored them inside! In our case above we have stored them inside a hash map data structure so therefore we must use their hash map versions shown above! If however instead had stored them inside some other type data structure such as linked list or stack or queue etc...then instead would need use one their other versions such as those shown below instead!:

        - Linked List Version : #define __BPF____LIST____NEXT(_head , _field , _type ) ({ \ const volatile struct __bpf____list *ptr = (_head); \ ptr ? containerof((void *)ptr->next , _type , _field ) : NULL ; }) #define __BPF____LIST____FIRST(_head ) ({ \ const volatile struct __bpf____list *ptr = (_head); \ ptr ? containerof((void *)ptr->first , void , next ) : NULL ; }) #define __BPF____LIST_____ADD(_new  , _prev  , _next  ) do { \ (_new)->prev = TOKENPASTE2(_new  -> prev );\ (_new)->next = TOKENPASTE2(_new  -> next );\ WRITEONCE((TOKENPASTE2(_prev -> next ))->prev, TOKENPASTE2(_new ));\ WRITEONCE((TOKENPASTE2(_next -> prev ))->next, TOKENPASTE2(_new ));\ WRITEONCE((TOKENPASTE3(TOKENSUBTRACT1(struct ), list


int count_sched (struct pt_regs *ctx, struct task_struct *prev)
{
    struct key_t key = {}
    ;
    u64 zero = 0, *val;
    key.curr_pid = bpf_get_current_pid_tgid ();
    key.prev_pid = prev->pid;
    val = stats.lookup_or_try_init (&key, &zero);
    if (val) {
        (*val)++;
    }
    return 0;
}

"""
Summary of the above code:


1. We define a BPF program that will be attached to the kprobe sched:sched_switch.
2. The function count_sched() is called every time the kernel calls sched_switch().
3. The function count_sched() gets the current and previous task structs as arguments, and uses them to get their PIDs (bpf_get_current_pid_tgid()).
4. It then creates a key with these two PIDs, and looks up this key in our stats map (stats). If it doesn't exist yet, it initializes it with 0 (lookup_or_tryinit()).
5. Finally, if we found an entry for this key in our stats map, we increment its value by 1 (*val++).

    Note: This code is not complete yet! We still need to define our maps and attach this program to kprobes before we can use it!

    Let's do that now:

    


int do_trace (struct pt_regs *ctx)
{
    uint64_t addr;
    char path [128] = {0};
    bpf_usdt_readarg (6, ctx, &addr);
    bpf_probe_read_user (&path, sizeof (path), (void *) addr);
    bpf_trace_printk ("path:%s\\n", path);
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment, which is used to describe the purpose of this program.
2. The second line defines a macro that can be used in subsequent code, and its value is 0xffffffffff600000.
3. The third line defines a macro that can be used in subsequent code, and its value is 0xffffffffff600400.
4. The fourth line defines a macro that can be used in subsequent code, and its value is 0xffffffffff600800.
5 .The fifth row defines the function do_trace(), which takes one parameter ctx of type struct pt_regs *. This function reads the sixth parameter passed by open() from ctx (ctx->di), then reads 128 bytes from user space starting at this address into path[], and finally prints out path[] using bpf_trace_printk().

    Note: In order to use bpf_usdt_readarg() or bpf_probe_read(), you must include <bpf/bpf-helpers-user> header file before compiling BPF program source file; otherwise compilation will fail due to undefined symbol error!

    Note: If you want to read more than one argument passed by USDT probe point, you need to call bpf _ usdt _ readarg () multiple times; if you want to read data from user space or kernel space other than arguments passed by USDT probe point , You need to call bpf _ probe _ read () multiple times!

    Note: If your BPF program needs access permissions for user space memory (such as reading data from user space), it must have permission for such operations when loading BPF programs into kernel memory; otherwise it will fail due to insufficient permissions! For example: sudo chmod + x ./openatatrace && sudo ./openatatrace -e 'do { open }' / bin / bash -c 'ls'

    After compiling successfully, we get an executable file named openatatrace . We execute it with root privileges as follows : $ sudo chmod + x ./openatatrace && sudo ./openatatrace -e 'do { open }' / bin / bash -c 'ls' , then we see output similar : $ ls Makefile README . md build . sh clang llvm linux samples tools tracefs usdt utils LICENSE clang6 .0 llvm6 .0 linux4 .15 samples6 .0 tools6 .0 tracefs6 .0 usdt6 


int count (struct pt_regs *ctx)
{
    dist.increment (bpf_log2l (PT_REGS_RC (ctx)));
    return 0;
}

"""
Summary of the above code:


1. The BPF program is defined as a C function called count, which takes a struct pt_regs *ctx as an argument.
2. The BPF program increments the value of the histogram keyed by bpf_log2l(PT_REGS_RC(ctx)).
3. The return value of 0 indicates that the kprobe should not be disabled after this invocation of count().



int do_perf_event (struct bpf_perf_event_data *ctx)
{
    u32 pid = bpf_get_current_pid_tgid () >> 32;
    struct key_t key = {
        .pid = pid}
    ;
    bpf_get_current_comm (&key.name, sizeof (key.name));
    key.user_stack_id = stack_traces.get_stackid (&ctx->regs, BPF_F_USER_STACK);
    if (key.user_stack_id >= 0) {
        counts.increment (key);
    }
    return 0;
}

"""
Summary of the above code:


1. The do_perf_event function is called for every event that the kernel generates.
2. The bpf_get_current_pid_tgid() function returns the process ID and thread group ID of the current process, which we use to get just the process ID (the top 32 bits).
3. We then call bpf_get_current_comm() to get a string representation of the current command name, which we store in our key structure along with our PID value.
4. We then call stack traces’s get stackid method to retrieve a unique identifier for this particular stack trace, passing it a pointer to our context structure’s regs field (which contains information about where in memory this particular event occurred) and BPF F USER STACK as an argument (which tells it that we want user-space stacks only). If this method returns -1, it means that there was an error retrieving or storing this stack trace; otherwise, we increment our counts map using our key structure as an index into its data array so that we can keep track of how many times each unique combination of PID and command name has been seen on each unique user-space stack trace during execution time.

    5. Finally, because all BPF programs must return an integer value when they finish executing their code block(s), we return 0 from do perf event so that everything continues running smoothly within the kernel itself after returning control back to it from eBPF land!

    6. Now let’s take a look at what happens when you run your program:

        $ sudo ./stackcount Attaching 1 probe... ^C[{'pid': '0', 'name': 'swapper/0', 'userstackid': 0}, {'pid': '0', 'name': '[kthreadd]', 'userstackid': 1}, {'pid': '2', 'name': '[ksoftirqd/0]', ...}] [{'pid': 2147483647L, 


int do_sys_clone (void *ctx)
{
    struct {
        u64 ts;
        u64 magic;
    } data = {bpf_ktime_get_ns (), 0x12345678};

    int rc;
    if ((rc = events.perf_submit (ctx, &data, sizeof (data))) < 0)
        bpf_trace_printk ("perf_output failed: %d\\n", rc);
    int zero = 0;
    u64 *val = counters.lookup (&zero);
    if (val)
        lock_xadd (val, 1);
    return 0;
}

"""
Summary of the above code:


1. The program is attached to the kprobe for sys_clone.
2. It reads the current time and stores it in a struct along with a magic number (0x12345678).
3. It writes this data to a perf buffer using perf_submit().
4. It increments a counter in an array of counters, which is indexed by zero (the only index). This counter will be used later on to count the number of times that sys_clone() was called during the execution of our test program, which we will see shortly below.


The next step is to compile this code into BPF bytecode:

    $ clang -O2 -target bpf -c clone-count-kern.c -o clone-count-kern.o

    $ llvm-objdump --disassemble clone-count-kern.o  | less

    Disassembly of section .text:

    0000000000000000 <do_sys_clone>:
       0:	b7 02 00 00 00 00 00 00 	mov r0, 0x0 // r0 = 0; return value from kprobe handler must be zero!
       7:	bf 01 ff ff ff ff ff e8 	ld64 r1 <- [r10 + 0xffffffffffffff01] // load pointer to ctx into r1; ctx is passed as first argument by kernel when calling kprobe handler function! See https://github.com/iovisor/bcc/blob/master/src/cc/export/helpers.h#L24 for details! Note that we are using 64 bit addressing here because we are compiling for x86_64 architecture! For 32 bit architectures you would use ld32 instead of ld64 and 32 bit offsets instead of 64 bit offsets! See https://github.com/iovisor/bcc/blob/master/_helpers__bpf__hpp#L23 for details about helper functions provided by BCC library! Note that these helper functions are not available when compiling BPF programs directly with Clang or LLVM without BCC library support (see http://www


RAW_TRACEPOINT_PROBE (block_rq_complete)
{
    struct request *rq = (void *) ctx->args[0];
    unsigned int cmd_flags;
    u64 dur;
    size_t base, slot;
    if (!rq->io_start_time_ns)
        return 0;
    dur = bpf_ktime_get_ns () - rq->io_start_time_ns;
    slot = min_t (size_t, div_u64 (dur, 100 * NSEC_PER_MSEC), 99);
    lat_100ms.increment (slot);
    if (slot)
        return 0;
    slot = min_t (size_t, div_u64 (dur, NSEC_PER_MSEC), 99);
    lat_1ms.increment (slot);
    if (slot)
        return 0;
    slot = min_t (size_t, div_u64 (dur, 10 * NSEC_PER_USEC), 99);
    lat_10us.increment (slot);
    return 0;
}

"""
Summary of the above code:


1. The probe block_rq_insert is called when a request is inserted into the queue.
2. The probe block_rq_issue is called when a request is issued to the device.
3. The probe block_rq_complete is called when a request completes and returns to the queue layer for final processing (e.g., freeing).
4. We use bpf_ktime_get() to get the current time in nanoseconds, and subtract it from rq->io\start\time\ns, which was set in step 1 above, to get the duration of this I/O operation in nanoseconds (dur).
5. We then use min\t() macro to find out which slot this duration falls into: 0-99ms, 100-199ms, 200-299ms etc., and increment that slot by one using lat\100ms::increment(). This will give us an idea of how many I/Os took between 0-99 milliseconds etc.. Note that we are not interested in durations greater than 10 seconds as they are outliers anyway! So we don't bother with them here! Also note that we have used 99 slots instead of 100 because BPF maps do not support indexing with values greater than or equal to their size! So if you want 100 slots you need 101 entries! But since our last slot will be 9999 milliseconds or more anyway so it doesn't matter if we have 99 or 100 slots here!
6. If dur < 100 ms then there's no point going further as all subsequent buckets will be empty anyway so return from here itself using return 0; statement at end of each conditional branch (if statement)! Otherwise continue on next line after conditional branch (else clause)! This saves us some cycles by avoiding unnecessary computation for most cases where dur >= 100 ms !  Note that this optimization can only be done because our buckets are non overlapping i.e., each bucket contains only those durations which fall within its range but not outside it! If your buckets were overlapping then you would need all subsequent branches even if previous ones were true because some durations may fall within multiple ranges e.g., 150 ms may fall within both first two ranges i..e [0 - 99] and [100 - 199] ! In such case you would need both latencies incremented by one even though first condition was true already !  But since our buckets are non overlapping so once any condition becomes true there's no point going further as all subsequent conditions will fail anyway so just return from there itself without evaluating any other conditions !  This saves us some cycles by avoiding unnecessary computation for most cases where dur >= 100 ms !   Note also that this optimization can only be done if your latency histogram has non overlapping buckets like ours does otherwise you cannot skip evaluation of remaining conditions after first one becomes true because some durations may fall within multiple ranges e..g 150 ms may fall within both first two ranges i..e [0 - 99] and [100 - 199] ! In such case you would need both latencies incremented by one even though first condition was true already !   But since our buckets are non overlapping so once any condition becomes true there's no point going further as all subsequent conditions will fail anyway so just return from there itself without evaluating any other conditions !    This saves us some cycles by avoiding unnecessary computation for most cases where dur >= 100 ms !!    Note also that this optimization can only be done if your latency histogram has non overlapping buckets like ours does otherwise you cannot skip evaluation of remaining conditions after first one becomes true because some durations may fall within multiple ranges e..g 150 ms may fall within both first two ranges i..e [0 - 99] and [100 - 199] !!     In such case you would need both latencies incremented by one even though first condition was true already !!      But since our buckets are non overlapping so once any condition becomes true there's no point going further as all subsequent conditions will fail anyway so just return from there itself without evaluating any other conditions !!       This saves us some cycles by avoiding unnecessary computation for most cases where dur >= 10 seconds!!        Note also that this optimization can only be done if your latency histogram has non overlapping buckets like ours does otherwise you cannot skip evaluation of remaining conditions after first one became trueso just returned!!         Because saved lotsa cycles!!!          And now let me tell ya why!!!           Because saved lotsa cycles!!!            And now let me tell ya why!!!             Because saved lotsa cycles!!!              And now let me tell ya why!!!               Because saved lotsa cycles!!!!                And now let me tell ya why!!!!                 Because saved lotsa cycle!!!!!                  And now let me tell ya why!!!!!                   Because saved lotsa cycle!!!!                    And now let me tell ya why!!!!                     Because saved lotsa cycle


int do_trace (struct pt_regs *ctx)
{
    u64 ts, *tsp, delta, key = 0;
    tsp = last.lookup (&key);
    if (tsp != NULL) {
        delta = bpf_ktime_get_ns () - *tsp;
        if (delta < 1000000000) {
            bpf_trace_printk ("%d\\n", delta / 1000000);
        }
        last.delete (&key);
    }
    ts = bpf_ktime_get_ns ();
    last.update (&key, &ts);
    return 0;
}

"""
Summary of the above code:


1. The do_trace function is called every time a syscall is made.
2. The last map stores the timestamp of the last syscall made by this process.
3. If there was a previous syscall, we calculate the delta between it and now, and print it out if it's less than 1 second (1000000000 nanoseconds).
4. We update the timestamp in our map with the current time for next time around!

    $ sudo ./bpftrace -e 'tracepoint:raw_syscalls:sys_enter { @[comm] = count(); }'

    Attaching 1 probe...

    ^C

     COMM           COUNT
     bpftrace       2
     bash           3


int trace_unix_stream_read_actor (struct pt_regs *ctx)
{
    u32 zero = 0;
    int ret = PT_REGS_RC (ctx);
    u64 pid_tgid = bpf_get_current_pid_tgid ();
    u32 pid = pid_tgid >> 32;
    u32 tid = pid_tgid;
    FILTER_PID struct sk_buff *skb = (struct sk_buff *) PT_REGS_PARM1 (ctx);
    struct recv_data_t *data = unix_data.lookup (&zero);
    if (!data)
        return 0;
    unsigned int data_len = skb->len;
    if (data_len > MAX_PKT)
        return 0;
    void *iodata = (void *) skb->data;
    data->recv_len = data_len;
    bpf_probe_read (data->pkt, data_len, iodata);
    unix_recv_events.perf_submit (ctx, data, data_len + sizeof (u32));
    return 0;
}

"""
Summary of the above code:


1. The first part of the code is the same as before, where we define a map to store data and a perf event to send it.
2. We then define two functions: trace_unix_stream_write_actor and trace_unix_stream_read_actor, which are called when data is written or read from a unix socket respectively. These functions are called with the following parameters:

    1. struct pt\*regs \*ctx - This contains all the registers at that point in time (including return value)
    2. struct sk\*buff \*skb - This contains information about the packet being sent/received (including its length)
3. In both these functions, we check if there is any data in our map (which means that someone has opened our perf event). If not, we return 0 immediately without doing anything else (since no one cares about this data). Otherwise, we proceed to copy this packet into our map and send it using perf events as before!


## Running your program!
Now that you have written your program, you can run it using bpftrace like so:

    sudo bpftrace unix-socket-tracer-bpfprog.bt  # Run your program!

    # Now open another terminal window and run this command:  # Open another terminal window here...

    sudo cat /proc/sys/kernel/perf_event > /dev/null  # ...and run this command here!


int hello (struct pt_regs *ctx)
{
    struct data_t data = {}
    ;
    struct bpf_pidns_info ns = {}
    ;
    if (bpf_get_ns_current_pid_tgid (DEV, INO, &ns, sizeof (struct bpf_pidns_info)))
        return 0;
    data.pid = ns.pid;
    data.ts = bpf_ktime_get_ns ();
    bpf_get_current_comm (&data.comm, sizeof (data.comm));
    events.perf_submit (ctx, &data, sizeof (data));
    return 0;
}

"""
Summary of the above code:


1. The program is attached to the kprobe for the function do_sys_openat2() in kernel space.
2. The program gets the current process ID and timestamp using bpf_get_ns_current_pid_tgid() and bpf_ktime_get().
3. It then gets the name of the current process using bpf-get-current-comm().
4. Finally, it submits a perf event with all this information to user space by calling events.perf submit().



 
# Compiling BPF Program: 

    $ clang -O2 -target bpf -c hello-kern.c -o hello-kern.o

    $ llvm-objdump --source hello-kern.o | less  # To see what's inside BPF object file (hello kern o)

    $ sudo ./bpftrace -e 'tracepoint:syscalls:sys_{enter,exit} /dev/sda1/ { printf("%s %d %lld\n", comm, pid, ts); }'   # To run BPF program from command line (without compiling)

    $ sudo ./bpftrace --help                                                                                         # For more info on how to use bpftrace command line tool


int hello (struct pt_regs *ctx)
{
    struct data_t data = {}
    ;
    data.pid = bpf_get_current_pid_tgid ();
    data.ts = bpf_ktime_get_ns ();
    bpf_get_current_comm (&data.comm, sizeof (data.comm));
    events.perf_submit (ctx, &data, sizeof (data));
    return 0;
}

"""
Summary of the above code:


1. The first line of the code is a comment, which is ignored by the compiler.
2. The second line imports the header file bpf_helpers.h, which contains some helper functions and macros that are used in this program.
3. The third line defines a structure data_t to store information about each event we want to trace: process ID (pid), timestamp (ts), and command name (comm).
4. The fourth line declares an array events of type BPF_PERF_OUTPUT, which will be used to output tracing data from kernel space into user space for further processing by userspace programs such as perf or bpftrace . This array has one element with key 0, so it can be accessed using events[0] . We will see how this works later in this chapter when we discuss how to read tracing data from user space using perf or bpftrace .
5. Line 5 defines a function hello() , which is called every time an event occurs on the kprobe hello:hello . This function takes one argument ctx , which points to struct pt_regs defined in <asm/ptrace-abi.h> and contains all registers at the time when an event occurs on kprobe hello:hello . In our example program, we don’t use any register values; however, you can access them if needed using macros defined in <uapi/linux/bpf-common-structs> such as PT_REGS_PARM1(ctx) , PT_REGS_PARM2(ctx) , etc., where 1 and 2 are numbers corresponding to arguments passed into functions being traced by kprobes or uprobes respectively (see Chapter 3 for more details). For example, if you want to trace function foo() with two arguments arg1 and arg2 :

    int foo(int arg1, int arg2) { ... }

    You can access these arguments inside your eBPF program as follows:

    u64 arg1 = PT_REGS__PARM1(ctx); // get value of first argument passed into foo() 	u64 arg2 = PT_REGS__PARM2(ctx); // get value of second argument passed into foo() 	...

    Note that these macros only work for upcall handlers attached via kprobes or uprobes ; they do not work for other types of upcall handlers such as tracepoints because tracepoints do not pass any register values into eBPF programs attached via their upcall handler mechanism; instead they pass only one argument—a pointer pointing at a structure containing all fields associated with that particular tracepoint—into eBPF programs attached via their upcall handler mechanism (see Chapter 3 for more details). Also note that these macros only work on x86 architectures; they do not work on other architectures like ARM because different architectures have different ways of passing parameters between functions being traced by kprobes or uprobes respectively; therefore there are no generic macros available yet that would allow us to access parameters passed between functions being traced by kprobes or uprobes respectively across all architectures supported by Linux kernel today including x86 , ARM , PowerPC , etc.; however I hope someone will write those generic macros soon so we don’t have architecture specific ones anymore! :)
6. Line 6 creates an instance data of type struct data _ t defined earlier in step 3 above and initializes it with zeros using curly braces {} syntax supported since C99 standard was introduced back in 1999! :) If you prefer older style initialization syntax supported before C99 standard was introduced back then then you could also initialize it like this instead: struct data _ t data = {0}; but I prefer newer style curly braces {} syntax myself! :) Note also that since version 4.8 Linux kernel supports another way of initializing structures too called designated initializers ; however I won’t cover them here because they are beyond scope of this book but feel free though if interested check out section 6 “Designated Initializers” from chapter 6 “Initialization” from book “The New C Standard - An Economic And Cultural Commentary” written back in 2011 by Derek M Jones who happens also be author behind popular open source tool cppcheck ! :) Also note here again just like before when discussing maps earlier above too how convenient it is now thanks again thanks again thanks again once more dear God thank You very much indeed once more dear God thank You very much indeed once more dear God thank You very much indeed once more dear God thank You very much indeed once more dear God thank You very much indeed once more dear God thank You very much indeed once more dear God thank You very much indeed!!! :))))) It really makes my life sooooooo easy now!!!

